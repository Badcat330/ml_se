{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSE 2021: Mathematical Methods for Data Analysis\n",
    "\n",
    "## Homework 4\n",
    "\n",
    "**Warning 1**: You have 3 weeks for this assignemnt.  **it is better to start early (!)**\n",
    "\n",
    "**Warning 2**: it is critical to describe and explain what you are doing and why, use markdown cells\n",
    "\n",
    "\n",
    "### Contents\n",
    "\n",
    "#### Decision Trees - 7 points\n",
    "* [Task 1](#task1) (0.5 points)\n",
    "* [Task 2](#task2) (0.5 points)\n",
    "* [Task 3](#task3) (2 points)\n",
    "* [Task 4](#task4) (0.5 points)\n",
    "* [Task 5](#task5) (0.5 points)\n",
    "* [Task 6](#task6) (2 points)\n",
    "* [Task 7](#task7) (0.5 points)\n",
    "* [Task 8](#task8) (0.5 points)\n",
    "\n",
    "#### Ensembles - 3 points\n",
    "* [Task 1](#task2_1) (1 point)\n",
    "* [Task 2](#task2_2) (0.7 points)\n",
    "* [Task 3](#task2_3) (0.5 points)\n",
    "* [Task 4](#task2_4) (0.7 points)\n",
    "* [Task 5](#task2_5) (0.1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (11, 5)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you will be implementing decision tree for the regression by hands. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 <a id=\"task1\"></a> (0.5 points)\n",
    "\n",
    "Implement the function `H()` which calculates impurity criterion. We will be training regression tree, therefore, impurity criterion will be variance.\n",
    "\n",
    "* You cannot use loops\n",
    "* If `y` is empty, the function should return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(y):\n",
    "    \"\"\"\n",
    "    Calculate impurity criterion\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.array\n",
    "        array of objects target values in the node\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    H(R) : float\n",
    "        Impurity in the node (measuread by variance)\n",
    "    \"\"\"\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    \n",
    "    return y.var()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "assert np.allclose(H(np.array([4,2,2, 2])), 0.75)\n",
    "assert np.allclose(H(np.array([])), 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 <a id=\"task2\"></a>  (0.5 points)\n",
    "\n",
    "To find the best split in the node we need to calculate the cost function. Denote: \n",
    "- `R` all the object in the node\n",
    "- `j` index of the feature selected for the split\n",
    "- `t` threshold\n",
    "- `R_l` and `R_r` objects in the left and right child nodes correspondingly\n",
    "\n",
    "We get the following cost function:\n",
    "\n",
    "$$\n",
    "Q(R, j, t) =\\frac{|R_\\ell|}{|R|}H(R_\\ell) + \\frac{|R_r|}{|R|}H(R_r) \\to \\min_{j, t},\n",
    "$$\n",
    "\n",
    "Implement the function `Q`, which should calculate value of the cost function for a given feature and threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(X, y, j, t):\n",
    "    \"\"\"\n",
    "    Calculate cost function\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        array of objects in the node \n",
    "    y : ndarray\n",
    "        array of target values in the node \n",
    "    j : int\n",
    "        feature index (column in X)\n",
    "    t : float\n",
    "        threshold\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Q : float\n",
    "        Value of the cost function\n",
    "    \"\"\"   \n",
    "\n",
    "    yr = y[X[:,j] > t]\n",
    "    yl = y[X[:,j] <= t]\n",
    "    \n",
    "    return yl.size / y.size * H(yl) + yr.size / y.size * H(yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 <a id=\"task3\"></a>  (2 points)\n",
    "\n",
    "Now, let's implement `MyDecisionTreeRegressor` class. More specifically, you need to implement the following methods:\n",
    "\n",
    "- `best_split`\n",
    "- `grow_tree`\n",
    "- `get_prediction`\n",
    "\n",
    "Read docstrings for more details. Do not forget to use function `Q` implemented above, when finding the `best_split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Class for a decision tree node.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    right : Node() or None\n",
    "        Right child\n",
    "    right : Node() or None\n",
    "        Left child\n",
    "    threshold: float\n",
    "        \n",
    "    column: int\n",
    "        \n",
    "    depth: int\n",
    "        \n",
    "    prediction: float\n",
    "        prediction of the target value in the node (average values calculated on a train dataset)\n",
    "    is_terminal:bool\n",
    "        indicates whether it is a terminal node (leaf) or not\n",
    "    \"\"\"    \n",
    "    def __init__(self):        \n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        self.threshold = None\n",
    "        self.column = None\n",
    "        self.depth = None\n",
    "        self.is_terminal = False\n",
    "        self.prediction = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        if self.is_terminal:\n",
    "            node_desc = 'Pred: {:.2f}'.format(self.prediction)\n",
    "        else:\n",
    "            node_desc = 'Col {}, t {:.2f}, Pred: {:.2f}'.format(self.column, self.threshold, self.prediction)\n",
    "        return node_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "class MyDecisionTreeRegressor(RegressorMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Class for a Decision Tree Regressor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_depth : int\n",
    "        Max depth of a decision tree.\n",
    "    min_samples_split : int\n",
    "        Minimal number of samples (objects) in a node to make a split.\n",
    "    \"\"\" \n",
    "    def __init__(self, max_depth=3, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "            \n",
    "    def best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Find the best split in terms of Q of data in a given decision tree node. \n",
    "        Try all features and thresholds. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_objects, n_features)\n",
    "            Objects in the parent node\n",
    "        y : ndarray, shape (n_objects, )\n",
    "            1D array with the object labels. \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        best_split_column : int\n",
    "            Index of the best split column\n",
    "        best_threshold : float\n",
    "            The best split condition.\n",
    "        X_left : ndarray, shape (n_objects_l, n_features)\n",
    "            Objects in the left child\n",
    "        y_left : ndarray, shape (n_objects_l, )\n",
    "            Objects labels in the left child. \n",
    "        X_right : ndarray, shape (n_objects_r, n_features)\n",
    "            Objects in the right child\n",
    "        y_right : ndarray, shape (n_objects_r, )\n",
    "            Objects labels in the right child. \n",
    "        \"\"\"\n",
    "        \n",
    "        # To store best split parameters\n",
    "        best_split_column = None\n",
    "        best_threshold = None\n",
    "        # without splitting\n",
    "        best_cost = H(y) \n",
    "        \n",
    "        for feature in range(X.shape[1]):\n",
    "            for threshold in np.unique(X[:,feature]):\n",
    "                new_Q = Q(X, y, feature, threshold)\n",
    "                if new_Q <= best_cost:\n",
    "                    best_split_column = feature\n",
    "                    best_threshold = threshold\n",
    "                    best_cost = new_Q\n",
    "                \n",
    "        \n",
    "        \n",
    "        X_left = X[X[:,best_split_column] <= best_threshold]\n",
    "        X_right = X[X[:,best_split_column] > best_threshold]\n",
    "        \n",
    "        y_left = y[X[:,best_split_column] <= best_threshold]\n",
    "        y_right = y[X[:,best_split_column] > best_threshold]\n",
    "        return best_split_column, best_threshold, X_left, y_left, X_right, y_right\n",
    "    \n",
    "    def is_terminal(self, node, y):\n",
    "        \"\"\"\n",
    "        Check terminality conditions based on `max_depth` and `min_samples_split` parameters for a given node. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node, \n",
    "            \n",
    "        y : ndarray, shape (n_objects, )\n",
    "            Object labels. \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Is_termial : bool\n",
    "            If True, node is terminal\n",
    "        \"\"\"\n",
    "        if node.depth >= self.max_depth:    \n",
    "            return True\n",
    "        if len(y) < self.min_samples_split:   \n",
    "            return True\n",
    "        return False\n",
    "        \n",
    "    def grow_tree(self, node, X, y):\n",
    "        \"\"\"\n",
    "        Reccurently grow the tree from the `node` using a `X` and `y` as a dataset:\n",
    "         - check terminality conditions\n",
    "         - find best split if node is not terminal\n",
    "         - add child nodes to the node\n",
    "         - call the function recursively for the added child nodes\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node() object\n",
    "            Current node of the decision tree.\n",
    "        X : ndarray, shape (n_objects, n_features)\n",
    "            Objects \n",
    "        y : ndarray, shape (n_objects)\n",
    "            Labels\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.is_terminal(node, y):\n",
    "            node.is_terminal = True\n",
    "            return\n",
    "        \n",
    "        # find best split and fill threshold and column fields\n",
    "        best_split_column, best_threshold, X_left, y_left, X_right, y_right = self.best_split(X, y)\n",
    "        node.threshold = best_threshold\n",
    "        node.column = best_split_column\n",
    "        \n",
    "        # Add child\n",
    "        child_left = Node()\n",
    "        child_right = Node()\n",
    "        child_left.depth = node.depth + 1\n",
    "        child_right.depth = node.depth + 1\n",
    "        \n",
    "        if y_left.size != 0:\n",
    "            child_left.prediction = np.mean(y_left)\n",
    "        else:\n",
    "            child_left.prediction = 0\n",
    "            \n",
    "        if y_right.size != 0:\n",
    "            child_right.prediction = np.mean(y_right)\n",
    "        else:\n",
    "            child_right.prediction = 0\n",
    "        \n",
    "        node.left = child_left\n",
    "        node.right = child_right\n",
    "        \n",
    "        # Reccurently grow the tree\n",
    "        self.grow_tree(child_left, X_left, y_left)\n",
    "        self.grow_tree(child_right, X_right, y_right)\n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the Decision Tree Regressor.\n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        y : ndarray, shape (n_samples,) or (n_samples, n_outputs)\n",
    "            The target values.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        X, y = check_X_y(X, y, accept_sparse=False)\n",
    "        self.is_fitted_ = True\n",
    "        \n",
    "        # Initialize the tree (root node)\n",
    "        self.tree_ = Node()                             \n",
    "        self.tree_.depth = 1                            \n",
    "        self.tree_.prediction = np.mean(y)\n",
    "        \n",
    "        # Grow the tree\n",
    "        self.grow_tree(self.tree_, X, y)\n",
    "        return self        \n",
    "    \n",
    "    def get_prediction(self, node, x):\n",
    "        \"\"\"\n",
    "        Get prediction for an object `x`\n",
    "            - Return prediction of the `node` if it is terminal\n",
    "            - Otherwise, recursively call the function to get predictions of the proper child\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node() object\n",
    "            Current node of the decision tree.\n",
    "        x : ndarray, shape (n_features,)\n",
    "            Array of feature values of one object.\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : float\n",
    "            Prediction for an object x\n",
    "        \"\"\"\n",
    "        if node.is_terminal:\n",
    "            y_pred = node.prediction\n",
    "        else:\n",
    "            if x[node.column] > node.threshold:\n",
    "                y_pred = self.get_prediction(node.right, x)\n",
    "            else:\n",
    "                y_pred = self.get_prediction(node.left, x)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" \n",
    "        Get prediction for each object in X\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            Returns predictions.\n",
    "        \"\"\"\n",
    "        # Check input and that `fit` had been called\n",
    "        X = check_array(X, accept_sparse=False)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        \n",
    "        # Get predictions\n",
    "        y_predicted = []\n",
    "        for x in X:\n",
    "            y_curr = self.get_prediction(self.tree_, x)\n",
    "            y_predicted.append(y_curr)\n",
    "        return np.array(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/estimator_checks.py:3063: FutureWarning: As of scikit-learn 0.23, estimators should expose a n_features_in_ attribute, unless the 'no_validation' tag is True. This attribute should be equal to the number of features passed to the fit method. An error will be raised from version 1.0 (renaming of 0.25) when calling check_estimator(). See SLEP010: https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep010/proposal.html\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/utils/estimator_checks.py:3105: FutureWarning: As of scikit-learn 0.23, estimators should have a 'requires_y' tag set to the appropriate value. The default value of the tag is False. An error will be raised from version 1.0 when calling check_estimator() if the tag isn't properly set.\n",
      "  warnings.warn(warning_msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# check yourself\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "\n",
    "check_estimator(MyDecisionTreeRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 <a id=\"task4\"></a>  (0.5 points)\n",
    "\n",
    "Load boston dataset and split it on the train ($70\\%$) and test ($30\\%$). Fit Decision Tree of depth 1 and make the following plot:\n",
    "\n",
    "- Scatter plot of the traning points (selected for split feature on the x-axis, target variable on the y-axis)\n",
    "- Fitted model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "0       15.3  396.90   4.98    24.0  \n",
       "1       17.8  396.90   9.14    21.6  \n",
       "2       17.8  392.83   4.03    34.7  \n",
       "3       18.7  394.63   2.94    33.4  \n",
       "4       18.7  396.90   5.33    36.2  \n",
       "..       ...     ...    ...     ...  \n",
       "501     21.0  391.99   9.67    22.4  \n",
       "502     21.0  396.90   9.08    20.6  \n",
       "503     21.0  396.90   5.64    23.9  \n",
       "504     21.0  393.45   6.48    22.0  \n",
       "505     21.0  396.90   7.88    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston['data']\n",
    "y = boston['target']\n",
    "dataPD = pd.DataFrame(data= np.c_[boston['data'], boston['target']], \n",
    "                      columns=np.append(boston['feature_names'], ['target']))\n",
    "dataPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyDecisionTreeRegressor(max_depth=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=True)\n",
    "model = MyDecisionTreeRegressor(max_depth=2)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAGpCAYAAABcXji6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABP30lEQVR4nO3df3xU5Z33//eVEIQAZpcB3fojif3WBSwBDNSVYq1tatciavVBb0uDS9VduthW2l1RemdXxW0et7a9VboVu9nawsrY9cfKVlvqqoi3xdq1aKNYpP7oJlTbRQk1JQYWCNf3j5OByeScM2cmM+ecmXk9H488QubHOdecGciHz/W5Ppex1goAAADFVxX1AAAAACoFgRcAAEBICLwAAABCQuAFAAAQEgIvAACAkIyKegBBTJo0yTY2NkY9DAAAgKyee+653dbayW73lUTg1djYqK1bt0Y9DAAAgKyMMd1e9zHVCAAAEBICLwAAgJAQeAEAAISkJGq83Bw8eFBvvPGG9u/fH/VQkIcxY8bopJNOUk1NTdRDAQAgNCUbeL3xxhuaMGGCGhsbZYyJejjIgbVWPT09euONN3TKKadEPRwAAEJTslON+/fvVyKRIOgqQcYYJRIJspUAgIpTsoGXJIKuEsZ7BwCoRCUdeAEAAJQSAq+YePLJJ7VgwQJJ0kMPPaSbb77Z87HvvPOO1qxZc+Tn3/72t1q4cGFBxnHOOedkbVb7k5/8RO9///s1a9YsPfPMM9q4cWNBzg0AQLkj8CqygYGBnJ9z4YUXauXKlZ73ZwZeJ5xwgh544IG8xpePZDKpr3zlK+rs7NSvfvUrAi8AAAIi8MpTV1eXpk6dqtbWVk2bNk0LFy5Uf3+/JGeLo+uuu07Nzc26//779eijj2ru3Llqbm7Wpz71KfX19UmSHnnkEU2dOlXNzc168MEHjxx77dq1+sIXviBJ2rVrly6++GLNnDlTM2fO1E9/+lOtXLlSr7/+umbNmqUVK1aoq6tL06dPl+QsOrj88svV1NSk008/XZs3bz5yzEsuuUTnnXeeTj31VF177bVZX6PbuL/zne/ovvvu09///d9r0aJFuv7663Xvvfdq1qxZuvfeewt6jQEAKDcl205iiHuKVKj9Get7969+9Svdddddmjdvnq644gqtWbNG11xzjSQpkUjo+eef1+7du3XJJZfo8ccf17hx43TLLbfo1ltv1bXXXqu/+qu/0hNPPKH3ve99uvTSS13PcfXVV+vDH/6wNmzYoIGBAfX19enmm2/WSy+9pM7OTklOEJhyxx13yBijbdu2aceOHfr4xz+uV155RZLU2dmpX/ziFzrmmGM0ZcoUffGLX9TJJ5/set7du3frq1/96rBxX3/99dqyZYsWLFighQsXau3atdq6dau+9a1v5XhxAQCoPEXNeBljuowx24wxncaYrYO3TTTGPGaMeXXw+x8XcwzFdPLJJ2vevHmSpMWLF2vLli1H7ksFUj/72c+0fft2zZs3T7NmzdK6devU3d2tHTt26JRTTtGpp54qY4wWL17seo4nnnhCy5YtkyRVV1errq7Od0xbtmw5cqypU6eqoaHhSODV0tKiuro6jRkzRqeddpq6uz338PQcNwAAyF8YU40fsdbOstbOGfx5paRN1tpTJW0a/HlkPmOL85VFZkuE9J/HjRsnyWkWeu6556qzs1OdnZ3avn277rrrrhG/5Hwcc8wxR/5cXV2tQ4cOeT42TuOuVMmk1NgoVVU535PJqEcUb1yv4cK+JsltSTXe3qiqVVVqvL1RyW3xehPCGl/6eSZ9bZImfW2S6zmT25Ka9LVJMquMzCqjSV+bFOo187seYb6Xcf/cFFoUNV4XSVo3+Od1kj4ZwRgKYufOnXrmmWckSffcc4/OOuusYY8588wz9fTTT+u1116TJL377rt65ZVXNHXqVHV1den111+XJH3/+993PUdLS4vuvPNOSU6hfm9vryZMmKC9e/e6Pv5DH/qQkoP/ur7yyivauXOnpkyZkvNr8xp3Jr+xIH/JpLR0qdTdLVnrfF+6lGDCC9druLCvSXJbUksfXqru3m5ZWXX3dmvpw0tj80s0rPFlnqdnX4969vUMO2dyW1KX//vl6tnXc+S5Pft6dMUPrgjlmvldjzDfy7h/boqh2IGXlfSoMeY5Y8zSwduOt9b+bvDP/y3p+CKPoWimTJmiO+64Q9OmTdPvf//7I1OC6SZPnqy1a9dq0aJFmjFjhubOnasdO3ZozJgx6ujo0Pnnn6/m5mYdd9xxrudYvXq1Nm/erKamJs2ePVvbt29XIpHQvHnzNH36dK1YsWLI46+66iodPnxYTU1NuvTSS7V27dohma6gvMad6SMf+Yi2b99OcX2BtbVJg2s1jujvd27HcFyv4Yp6TYxxvtLPt6lN/QeHnrD/YL/aNsXjTQhrfG7ncTtn26Y2HTx8cNj9BwYOhHLN/K5HmO9l3D83xWCszT6llvfBjTnRWvumMeY4SY9J+qKkh6y1f5T2mN9ba4fVeQ0Gakslqb6+fnZmfdHLL7+sadOmFW3s2XR1dWnBggV66aWXIhtDqYv6PYyzqionS5HJGOnw4fDHE3dcr+GKek1SQVfaCapWVclq+AmNjA7fEP2bENb4vM6TeU5Jno8L45r5XQ+vsRVjXHH/3OTLGPNcWonVEEXNeFlr3xz8/pakDZLOkLTLGPOewYG9R9JbHs/tsNbOsdbOmTx5cjGHCcROfX1ut1c6rtdwYV+T+jr3A3vdHrawxhfkePV19b6PC+Oa+V2PMN/LuH9uiqFogZcxZpwxZkLqz5I+LuklSQ9JWjL4sCWSflCsMRRTY2Mj2S4UTXu7VFs79LbaWud2DMf1Gi7sa9Le0q7amqEnrK2pVXtLPN6EsMbndh63c7a3tKumqmbY/aOrR4dyzfyuR5jvZdw/N8VQzIzX8ZK2GGNekPSspB9Zax+RdLOkc40xr0r62ODPANK0tkodHVJDgzOr09Dg/NzaGvXI4onrNVzY16S1qVUdF3Sooa5BRkYNdQ3quKBDrU3xeBPCGl/meRJjE0qMTQw7Z2tTq773ye8pMTZx5LmJsQl996LvhnLN/K5HmO9l3D83xVDUGq9CmTNnjs3cP5D6oNLHewiUKJcaLwBHRVbjBQAASlel9dgKQ3lsGQQAAAoq1WMr1e4h1WNLUllPBRYbGa+YePLJJ7VgwQJJ0kMPPaSbb/YufXvnnXe0Zs2aIz//9re/1cKFC4syruuvv16PP/6472NuvPFGfeMb3xh2e+Y4AQCloxJ7bIWBwKvIBgYGcn7OhRdeqJUrvXdSygxoTjjhBD3wwAN5jc/PwMCAbrrpJn3sYx/L6/kEXgAQH7lOG+7s3ZnT7QiGwCtPXV1dmjp1qlpbWzVt2jQtXLhQ/YNtohsbG3XdddepublZ999/vx599FHNnTtXzc3N+tSnPqW+vj5J0iOPPKKpU6equblZDz744JFjr127Vl/4whckSbt27dLFF1+smTNnaubMmfrpT3+qlStX6vXXX9esWbO0YsUKdXV1afr06ZKk/fv36/LLL1dTU5NOP/10bd68+cgxL7nkEp133nk69dRTde2117q+rsyxf/aznz0S1G3cuFFTp07V7NmzdfXVVx/J0EnS9u3bdc455+i9732vvvnNb0rSsHECAKKRz9Y8ldhjKwxlUeO1yqwqynFvsDf43v+rX/1Kd911l+bNm6crrrhCa9as0TXXXCNJSiQSev7557V7925dcsklevzxxzVu3DjdcsstuvXWW3Xttdfqr/7qr/TEE0/ofe97ny699FLXc1x99dX68Ic/rA0bNmhgYEB9fX26+eab9dJLL6mzs1OSEwSm3HHHHTLGaNu2bdqxY4c+/vGPH9ljsbOzU7/4xS90zDHHaMqUKfriF7+ok08+edg5U2OXnOBQcgK6z33uc3rqqad0yimnaNGiRUOes2PHDm3evFl79+7VlClTtGzZsmHjBABEw2/a0Kteq72lfUiNl1T+PbbCQMZrBE4++WTNmzdPkrR48WJt2bLlyH2pQOpnP/uZtm/frnnz5mnWrFlat26duru7tWPHDp1yyik69dRTZYzR4sWLXc/xxBNPHNkDsrq6WnV1db5j2rJly5FjTZ06VQ0NDUcCr5aWFtXV1WnMmDE67bTTlLkNU+bY0+3YsUPvfe97dcopp0jSsMDr/PPP1zHHHKNJkybpuOOO065du3zHCQAITz7ThpXYYysMZZHxypaZKhaTsUls+s/jxo2TJFlrde655+r73//+kMdGkQVK3yy7urpahw4dcn1cauzFODYAIHz1dfXq7h3+n+1s04aphqooHDJeI7Bz504988wzkqR77rlHZ5111rDHnHnmmXr66af12muvSZLeffddvfLKK5o6daq6urr0+uuvS9KwwCylpaVFd955pySn2L23t1cTJkzQ3r17XR//oQ99SMmkM2f/yiuvaOfOnZoyZcrIXqikKVOm6Ne//vWRac17770363P8xgkACE8lbs0TVwReIzBlyhTdcccdmjZtmn7/+98fmRJMN3nyZK1du1aLFi3SjBkzNHfuXO3YsUNjxoxRR0eHzj//fDU3N+u4445zPcfq1au1efNmNTU1afbs2dq+fbsSiYTmzZun6dOnDytav+qqq3T48GE1NTXp0ksv1dq1a4dko/I1duxYrVmzRuedd55mz56tCRMmZJ329BsnACA8TBvGB1sG5amrq0sLFiyoqI2y+/r6NH78eFlr9fnPf16nnnqqvvzlL+d9vKjfQwB5YssgwBdbBqEg/vmf/1mzZs3S+9//fvX29upzn/tc1EMCAKCklEVxfRQaGxsrKtslSV/+8pdHlOECAKDSkfECAAAICYEXAAAB5LrlDuCGqUYAALJIbbmT6uKe2nJHEisDkRMyXgAAZOG35Q6QCwKvPL3zzjtas2aNJOnJJ58csmF0oaRvUB1E+mbZmc455xxltuQAAASTz5Y7gBsCrzylB15BDQwMFGk0AIBi8tpaJ9uWO0AmAq88rVy5Uq+//rpmzZqlFStWqK+vTwsXLtTUqVPV2tqqVGPaxsZGXXfddWpubtb999+vRx99VHPnzlVzc7M+9alPqa+v78jxTjvtNM2YMUPXXHPNkfM89dRT+uAHP6j3vve9R7Jf1lqtWLFC06dPV1NTk+v2Pfv27dOnP/1pTZs2TRdffLH27dsXwlUBgPKSKqjv7u2W0dD9edlyB/koj+L6jM2qC8anK/PNN9+sl156SZ2dnXryySd10UUX6Ze//KVOOOEEzZs3T08//fSRvRsTiYSef/557d69W5dccokef/xxjRs3TrfccotuvfVWff7zn9eGDRu0Y8cOGWP0zjvvHDnP7373O23ZskU7duzQhRdeqIULF+rBBx9UZ2enXnjhBe3evVsf+MAHdPbZZw8Z35133qna2lq9/PLLevHFF9Xc3FyUSwQA5SqzoN7KysjIyqqhrkHtLe0U1iNn5RF4xcAZZ5yhk046SZI0a9YsdXV1HQm8Lr30UknSz372M23fvl3z5s2TJB04cEBz585VXV2dxowZoyuvvFILFiwYUi/2yU9+UlVVVTrttNO0a9cuSdKWLVu0aNEiVVdX6/jjj9eHP/xh/fznP9eMGTOOPO+pp57S1VdfLUmaMWPGkPsAANm5FdSngq6uL3VFMyiUvPIIvGKwX1j6RtTV1dU6dOjQkZ/HjRsnyZkiPPfcc/X9739/2POfffZZbdq0SQ888IC+9a1v6Yknnhh23FLYVxMAygUF9SgGarzyNGHCBO3duzen55x55pl6+umn9dprr0mS3n33Xb3yyivq6+tTb2+v5s+fr9tuu00vvPCC73E+9KEP6d5779XAwIDefvttPfXUUzrjjDOGPObss8/WPffcI0l66aWX9OKLL+Y0VgCodBTUoxjKI+MVgUQioXnz5mn69OkaO3asjj/++KzPmTx5stauXatFixbpf/7nfyRJX/3qVzVhwgRddNFF2r9/v6y1uvXWW32Pc/HFF+uZZ57RzJkzZYzR1772Nf3Jn/yJurq6jjxm2bJluvzyyzVt2jRNmzZNs2fPHtHrBYBK097SPqTGS6KgHiNnSmH6as6cOTazB9XLL7+sadOmRTQiFALvIVCiUguaSuD3x0gltyXVtqlNO3t3qr6unoJ6BGKMec5aO8ftPjJeAAB4aG1qJdBCQVHjBQAAEBICLwAAKkSqIWzVqio13t6o5LZk1EOqOEw1AgBQATIbwnb3dmvpw0slienUEJHxAgCgArg1hO0/2K+2TW0RjagyEXgBAFABaAgbDwReIzB+/Pisj/nmN7+padOmqbW1Vf/+7/+u7du3F/wcAABkQ0PYeCDwKrI1a9boscceUzKZzCvwAgDkj2Lyo9pb2lVbUzvkNhrChq9iAq9kUmpslKqqnO/JAv/d+/rXv64PfOADmjFjhm644QZJ0l//9V/r17/+tT7xiU+ovb1dDz30kFasWKFZs2bp9ddfH/L8Xbt26eKLL9bMmTM1c+ZM/fSnPx1yf19fn1paWtTc3Kympib94Ac/kORsO3T++edr5syZmj59uu69915J0sqVK3XaaadpxowZuuaaawr7YgGgBKSKybt7u2VljxSThxV8xS3oa21qVccFHWqoa5CRUUNdgzou6KCwPmQVsaoxmZSWLpX6B2sKu7udnyWptQCft0cffVSvvvqqnn32WVlrdeGFF+qpp57St7/9bT3yyCPavHmzJk2apFdffVULFizQwoULhx3j6quv1oc//GFt2LBBAwMD6uvrG3L/mDFjtGHDBh177LHavXu3zjzzTF144YV65JFHdMIJJ+hHP/qRJKm3t1c9PT3asGGDduzYIWOM3nnnnZG/SAAoMX7F5MUONuK6gpCGsNGriIxXW9vRoCulv9+5vRAeffRRPfroozr99NPV3NysHTt26NVXX83pGE888YSWLVsmSaqurlZdXd2Q+621+t//+39rxowZ+tjHPqY333xTu3btUlNTkx577DFdd911+slPfqK6ujrV1dVpzJgxuvLKK/Xggw+qtrbW7ZQAUNaiLCZnBSG8VETgtdPj75jX7bmy1uorX/mKOjs71dnZqddee01XXnllYQ4+KJlM6u2339Zzzz2nzs5OHX/88dq/f7/+9E//VM8//7yampr0d3/3d7rppps0atQoPfvss1q4cKF++MMf6rzzzivoWACgFERZTM4KQnipiMCr3uPvmNftufrzP/9zffe73z0yPfjmm2/qrbfeGva4CRMmaO/eva7HaGlp0Z133ilJGhgYUG9v75D7e3t7ddxxx6mmpkabN29Wd3e3JOm3v/2tamtrtXjxYq1YsULPP/+8+vr61Nvbq/nz5+u2227TCy+8UJgXCgAlJMpiclYQwktFBF7t7VLmbFttrXN7IXz84x/XZz7zGc2dO1dNTU1auHCha4D16U9/Wl//+td1+umnDyuuX716tTZv3qympibNnj172OrH1tZWbd26VU1NTfqXf/kXTZ06VZK0bds2nXHGGZo1a5ZWrVqlv/u7v9PevXu1YMECzZgxQ2eddZZuvfXWwrxQACghXsXkkope9M4KQngx1tqox5DVnDlz7NatW4fc9vLLL2vatGmBj5FMOjVdO3c6ma729sIU1iN/ub6HAGLCGOd7Cfz+yJRZ9C45AVExVvcltyXVtqlNO3t3qr6uXu0t7RS2VwhjzHPW2jmu91VK4IX44T0ESlQJB16Ntzequ7d72O0NdQ3q+lJX+AMKGcFgOPwCr4poJwEAgFTZRe9xbXFRaSqixgsAAKmyi95pcREPBF4AgIpRyUXvlZztixMCLwBAxQiybU7ctvoplErO9sUJNV4AgIrit21OOddBtbe0u67orIRsX5yQ8Sqg+fPnZ90X8ZxzzlHmCk1J6uzs1MaNG3M6n9exAAD5Kec6KDbJjgcyXgVgrZW1NufAKV1nZ6e2bt2q+fPnF3BkAIBclHsdFJtkR69iMl6FnrPv6urSlClT9Bd/8ReaPn26fvOb36ixsVG7d++WJP3DP/yDpkyZorPOOkuLFi3SN77xjSPPvf/++3XGGWfoT//0T/WTn/xEBw4c0PXXX697771Xs2bN0r333jvkXAMDA7rmmms0ffp0zZgxQ//4j/84bDzLli3TnDlz9P73v1833HDDkdtXrlyp0047TTNmzNA111xz5PzTp0/XzJkzdfbZZ4/oOgBAOanUOqhyrWuLo4rIeBVrzv7VV1/VunXrdOaZZw65/ec//7n+7d/+TS+88IIOHjyo5uZmzZ49+8j9hw4d0rPPPquNGzdq1apVevzxx3XTTTdp69at+ta3vjXsPB0dHerq6lJnZ6dGjRqlPXv2DHtMe3u7Jk6cqIGBAbW0tOjFF1/UiSeeqA0bNmjHjh0yxhyZBr3pppv0H//xHzrxxBOzTo0CQCWpxDqocq5ri6OKyHgVa86+oaFhWNAlSU8//bQuuugijRkzRhMmTNAFF1ww5P5LLrlEkjR79mx1dXVlPc/jjz+uz33ucxo1yomTJ06cOOwx9913n5qbm3X66afrl7/8pbZv3666ujqNGTNGV155pR588EHVDm5YOW/ePH32s5/VP//zP2tgYCDXlw0AZasS66DKua4tjioi8CrWnP24cePyet4xxxwjSaqurtahQ4dGNAZJ+q//+i994xvf0KZNm/Tiiy/q/PPP1/79+zVq1Cg9++yzWrhwoX74wx/qvPPOkyR9+9vf1le/+lX95je/0ezZs9XT0zPiMQCoPOU6LdXa1KquL3Xp8A2H1fWlrrIOuqTyr2uLm4oIvMKes583b54efvhh7d+/X319ffrhD3+Y9TkTJkzQ3r17Xe8799xz9U//9E9HgrTMqcY//OEPGjdunOrq6rRr1y79+Mc/liT19fWpt7dX8+fP12233aYXXnhBkvT666/rz/7sz3TTTTdp8uTJ+s1vfjOSlwuggqQHWVb2yLRUuQVflaRS69qiUhGBV9idij/wgQ/owgsv1IwZM/SJT3xCTU1Nqqur833ORz7yEW3fvt21uP4v//IvVV9frxkzZmjmzJm65557htw/c+ZMnX766Zo6dao+85nPaN68eZKkvXv3asGCBZoxY4bOOuss3XrrrZKkFStWqKmpSdOnT9cHP/hBzZw5s4CvHkA5c5t+YlqqtFVyN/8oGFsCu8vPmTPHZvarevnllzVt2rTAxwh7R/a+vj6NHz9e/f39Ovvss9XR0aHm5uaina8U5foeAohe1aoqHb7R+b1hbjx6u5HR4RsORzMojFjYvyPLnTHmOWvtHLf7KmJVoxR+75KlS5dq+/bt2r9/v5YsWULQBaAsONNP3R63o1TR3ys8FRN4hS1zOhAAyoEz/bR4yG1MSwHBlXSNVylMk8Id7x1QmtKzIpXSbgEopJLNeI0ZM0Y9PT1KJBIyxkQ9HOTAWquenh6NGTMm6qEAGAFquoDclWzgddJJJ+mNN97Q22+/HfVQkIcxY8bopJNOinoYAACEquiBlzGmWtJWSW9aaxcYY06R9K+SEpKek3SZtfZArsetqanRKaecUtjBAgAAFFEYNV7LJb2c9vMtkm6z1r5P0u8lXRnCGAAAACJX1MDLGHOSpPMlfWfwZyPpo5IeGHzIOkmfLOYYAAAA4qLYGa/bJV0rKVWBmZD0jrU2tUHhG5JOdHuiMWapMWarMWYrdVwAAKAcFC3wMsYskPSWtfa5fJ5vre2w1s6x1s6ZPHlygUcHAAAQvmIW18+TdKExZr6kMZKOlbRa0h8ZY0YNZr1OkvRmEccAAAAQG0XLeFlrv2KtPcla2yjp05KesNa2StosaeHgw5ZI+kGxxgAAABAnUXSuv07S3xhjXpNT83VXBGMAAAAIXSgNVK21T0p6cvDPv5Z0RhjnBQAAiJOS3qsRAIBKktyWVOPtjapaVaXG2xuV3JaMekjIUcluGQQAQCVJbktq6cNL1X+wX5LU3dutpQ8vlSQ2KS8hZLwAACgBbZvajgRdKf0H+9W2qS2iESEfBF4AAJSAnb07c7od8UTgBQBACaivq8/pdsQTgRcAACWgvaVdtTW1Q26rralVe0t7RCNCPgi8AAAoAa1Nreq4oEMNdQ0yMmqoa1DHBR0U1pcYVjUCABBjyW1JtW1q087enaqvq1d7SzvBVgkj8AIAIKZoIVF+mGoEAISORqDB0EKi/BB4AQDylk8AlcridPd2y8oeyeIQfA1HC4nyQ+AFAMhLvgEUWZzgaCFRfgi8AAB5Wfzg4rwCKLI4wdFCovwQeAEAAgsyHZgtgCKLExwtJMoPqxoBAIG1bWpTtl/52QKo9pb2ISv1JLI4flqbWgm0yoix1kY9hqzmzJljt27dGvUwAKDiVa2q0uEbnd8bq3RjtIMB8nCDvaHo5zDGPGetneN2H1ONAIDAmA4ERoapRgBAYM504GJJ0o033ijJmSbMte4ouS2p5T9erp59Pb6Pa6hrUNeXuvIcLRA/ZLwAAIGlB1f5Fnun2lBkC7okp1O7W0E/DVhRqsh4AQDycviGw3k9z62Pl5/MLXLYRgeljIwXACBUufbryuwNRgNWlDICLwBAqPIp0E8P1mjAilJG4AUACJVbN3ZJSoxNKDE24fqc9GCNBqwoZQReAIBQuXVjX3/Jeu2+drdWf2J11i1y2EYHpYwGqgCA3BjjfC/S74/ktqTaNrVpZ+9O1dfVq72lfVjRfJDHRDU2wK+BKoEXAFS4ZFJqa5N27pTq66X2dqnVL5YocuAVV5mrKaX8epih/NG5HgDgKpmUli6VurudOKq72/k5GaAtVmYvrat+dFVevbVKpScXqylRCGS8AKCCNTY6wVamhgapq8vjSYMZr3Httb79uIJkg0opi1S1qkpWw39nGpm8e5qhPJHxAgC42unRgcHr9nTZmqAGyQYFySLFJSPGakoUAoEXAFSweo+Ywev2XGXrrZWtJ1cqI9bd2y0re6RLfRTBF6spUQgEXgBQwdrbpdqMllq1tc7thZAtG5QtixSnuiq3NhhxnBJFvLFXIwBUsNTqxZxWNQ6qrcle45UtG9Te0u5a45V6Xty61Lc2tRJoYUTIeAFAhWttdQrpDx92vgcJuiQNy/4sm7Ms52xQtiwSdVUoN6xqBADkJsQ+XqW06hFIYVUjACD23FYvUleFckONFwAgcpmZrdTqRYm6KpQXMl4AgBEpRJ+tQq5ejEvfL8ANgRcAIG+F6rMVpJ9XkGAqTn2/ADcEXgAASc7+jI2NUlWV8z3Ifo3Lf7y8IJkqr1WKE8dO1KSvTdLiBxcHCqbi1PcLcEPgBQDIa7Ps5Lakevb1uN6XmcHKlrFy6wpfU1WjvQf2up7DK5jq7nXZeNLndiBsBF4AALW1Sf0ZvVD7+53bPZ/jk0VKz2C5Tf9d9uBlMquM7+rFY485VgcGDniew216stpUuz7W63YgbKxqBADktVm2X/f49I71btN/Vk4PMK/Vi8ltSS1+cLHvmN2mJwfsgOtjvW4HwkbGCwCQ12bZXnVZibGJIe0fsm3vkzltmMqQ+fHajqihrsH18V63A2Ej8AKAEpJPAXwQ+WyW7VaXVVtTq9WfWD3ktiDb+6QHZ24ZsnSJsQnPJqpeY8q2ZyQQFgIvACgR+RTAB9XaKnV0SA0Nzo5ADQ3Oz377NgbtKu8WDGVKD878MmTrL1mv3dfu9myoSqd7xB17NQJAiWhsdIKtTA0NzubWoclxr8bktqSW/3i55wrIzL0XG29vdF2F2FDXoK4vdeU1ZCBM7NUIAGUgnwJ4P17TloWczkzVa6UHXTVVNUqMTXhmpJguRDljVSMAlIj6eveMl18BvJfUtGWqhURq2vLpp6V164bfLvlPO3pxq9c6ePigxo8er93X7nZ9TioIa9vUpp29O1VfV6/2lnamC1EWmGoEgBKRGSxJTgF8tlosN17TltXV0oBL54Uh05k5TDVWrao60joinZHR4RsOBx5vUMltSQI2RI6pRgAoA/kUwHvxmp50C7r8Hp+N14rGICsdc8U+jSgFBF4AUEJaW53M0+HDzvd8gi7Je3qy2qPBez7TmVLx67XStyJasmEJ+zQi9gi8AKACefXtWro0935eforZ3iEzw+XVnT5bA1cgTBTXA0AFSmXKli+XegYXHI4dK82b53y1tTk1YNXVQ/dszCfDlr4VUCFla7SaUoxpTSBfZLwAoILt23f0zz09R1cwpjJiqZqvQjZrHanU9KJbr69MtKFA3LCqEQAqlF9DVsmnWWt3bg1UCyk1veiX6ao21TpsD7OqEZHxW9XIVCMAVKh8GrL63RdGK4ds04uZXfCBuGGqEQAqRGZH+okT3R9XX++9itHr9rBaOfgVyrMvI0oBgRcAVAC3Dbb37pVqaoY+LrWC0WvVo9fqRrdMVDFaOXgVyqf2cSToQtwReAFABWhrG9rxXpIOHJCOPda9IWuuzVq9MlGp29P7bTXe3ph3Jox9HFHqCLwAoMQF2dTarVBekvbsGdqQVTp6rLY2J8MVpFmrX4f6Qk5DFrMvGBCGoq1qNMaMkfSUpGPkFPE/YK29wRhziqR/lZSQ9Jyky6y1B/yOxapGAHAXZP/GZFK67DL3RYjpezAG3gvSZa9Gt9WGqUL3tk1trq0fUtODQLmJaq/G/5H0UWvtTEmzJJ1njDlT0i2SbrPWvk/S7yVdWcQxAEBZycxuLV8+fAoxveGp5PzZLegyZmjNltt0ZH+/tGRJ9v5dfpmobNOQQCUJpY+XMaZW0hZJyyT9SNKfWGsPGWPmSrrRWvvnfs8n4wUA7hkpL8Y4U4SSE6R5/VOffrvf44ZkvlwyXn68mp2S8UK5iirjJWNMtTGmU9Jbkh6T9Lqkd6y1hwYf8oakEz2eu9QYs9UYs/Xtt98u5jABIKsgdVTF5paR8pLe9sGrBUSqUWq2x0nDs2iSAhfLUxAPHFXUwMtaO2CtnSXpJElnSJqaw3M7rLVzrLVzJk+eXKwhAkBWbq0Yotg+x6tAPlNm24egrSHcHpcus3lq0GJ5CuKBo0LbMsgYc72kfZKuE1ONAEqI39Y6qcL0YvMrkE8kpPHjncCovt4JoDJXICaTTsbK7zGpxy1ZcnSPxnRHXu/gVKO5MeN+pg4BSRFtGWSMmSzpoLX2HWPMWEnnyims3yxpoZyVjUsk/aBYYwCAQshna51C8yuQX73av9WDdLQ3Vzapx7itbvRqnppCsTyQXTGnGt8jabMx5kVJP5f0mLX2h3IyXn9jjHlNTkuJu4o4BgAYsVy3zykGryDP2mABVS5ybZ6akurlVahmqUA5Cm2qcSSYagQQpcD9rYooDtOdR7hMNaZ6dkny7OdFTRcqRWSrGgGgHOSbAQoqyIrJIAXyYa+8dCuW99qzcfGDi8l+ASLjBQCRyiWb5lcg73YcY5ypyIYG72L6vPj08apaVSUr798rZL9QCfwyXgReABChQkwhJpPSX/zF0Yapbgo6NeoTeHk1S03H6keUO6YaASCmRrpiMpmULr/cP+iS3BugFoNbs9RMrH5EJSPwAoCQpddiVXn8Kxx0xWRbm3TwYLDHhtH+Ir1ZqpfU6kegEhF4AQhVHLbeiVJmF3y3RqVBemal5BJMpQK9Yl/31qZWdX2pS+svWc9WQUAGAi8AoYnL1jtR8tpvsbo6vxWTufQSGxgI97qzVRAwHMX1AEITq15UEamq8u5An61Oy00yKS1e7H+uqqosWwDlyqe4HgDF9QBiIg5b70St0F3w/TJj1jrBnFdAl+26V/q0MFAMBF4AQhOHrXeiFqQRaq4aPOrYU9d14kT3+71ul5gWBoqFwAtAaIoRdJSaYnTBL8Z1datFC6slBVDOCLwAhKbYW+8UW6Gm3lpbndqqw4ed70Ffv9f5s13XPXvcj+d1u8S0MFAsBF4AQpVv0BG1bFNvxa6HynZ+v+uazxQv08JAcRB4AUAAflNvYdRDjWTqL5+pSKaFgeIg8AKAAPym3sKoh8o29eeXcXObilyyxBmfV4bOa/oynbmxSpPaG5XcRsU9EFTWwMsYc0uQ2wCgnPlNvYVRD+V3/iAZt/SpyPZ2ad267Bm6zOlLSbr8trQHGaueQ926YsNSgi8goCAZr3NdbvtEoQcCoPyVcl8ov6m3YtVDpV+vvj5p9Gj38+eaccs3Q9fWJh380PAHHbD9atvEckcgCM/AyxizzBizTdIUY8yLaV//JenF8IYIoByUel8ov5WDxaiHyrxePT3O90Ri+PmDZNzSgzi33QMyH+95f537g3b2stwRCGKUz333SPqxpP8jaWXa7XuttT6LkAFgOL8sS6msbGxtdR9r6ra2Nic4qa93gq6RvC6363XwoDR+vLR799Db6+vdg6lUxi0VxLntEen2eL/7u3vrJQ0/WX0dyx2BIDwzXtbaXmttl7V2kaSTJX3UWtstqcoYc0poIwRQFsq9L1Sh22Tkcr2yZdy8Nub2eryX9nap5ifDHzTa1Kq9heWOQBBBiutvkHSdpK8M3jRa0vpiDgpA+aEvVG5yuV7ZGqj6Bbe5NLJtbZW+9+W0B1mjxKgGfffiDrU2lUjaEoiYsVl2lzfGdEo6XdLz1trTB2970Vo7o/jDc8yZM8du3bo1rNMBKAK36a7a2tLqXB+mQl6vxkb3qciGhqOrFXNijPM9y+8PoFIZY56z1s5xuy/IqsYD1onO7ODBxhVycAAqQ6lvFxS2Ql4vmqEC8REk43WNpFPltJX4P5KukHSPtfYfiz88BxkvABiZZLKAxf9kvABffhmvrIHX4AHOlfRxSUbSf1hrHyvsEP0ReAFAjBB4Ab5GOtUoa+1j1toV1tprwg66AADZlXJzWqCSBFnVuNcY84eMr98YYzYYY94bxiABIEx+QUyhApygxwnyuLg2p01uS6rx9kZVrapS4+3s6QhIwWq8/kHSG3IaqhpJn5b0/0l6XtIya+05RR4jU40AQuO3mlAqzEpDt3PU1EjHHivt2XO0BsvrfEuWSBs3Hq3X6utzOttnynvVorLUhAWYakxuS2rpw0vVf/Do4GtratVxAa0nUP5GVONljHnBWjsz47ZOa+0st/uKgcALwEgFLS73a70geW+309Aw/Jhe5/Q6R7raWmnsWPeAyphg5VXGOA1dc5W1lUWAwKvx9kZ19w5/kQ11Der6UlfugwJKiF/g5bdlUEq/MeZ/SXpg8OeFkvYP/pnKSgCxlQp8uruHBiupqThpePCVb4f9zGNmBi/p9wfp1t/f791tPmhN+8SJwR6XqRDbO3nt3ciejqh0QYrrWyVdJuktSbsG/7zYGDNW0heKODYAyFt63ZM0PFjp75eWLx/6+MZG76Bm4sTsXfZTwYnkHbwsXx5et/69e/Or8yrE9k5eezeypyMqnW/gZYyplnSVtfYCa+0ka+3kwT+/Zq3dZ63dEtI4ASAnQfYn7OlxApPMIM3N3r3S/PnDG5FmSgUnXkFKT0+w40hSIhHscZJTfJ/pwIGjgWAuCrG9U3tLu2prhg6+toY9HQHfwMtaOyDprJDGAgAFEzQ709YWLEg7cEC67z6n7srPxIn+mTPJKYxPdaX3s3q187jqav/H1dZ613Llswl5ITrdtza1quOCDjXUNcjIqKGugcJ6QMGK6++UdKKk+yW9m7rdWvtgcYd2FMX1AHIVpIBdKmwv0NGjneMcPJj9nKlAyWuciYS0e7fz56oq7/E1NDgZtI4OaWDA/Tjjx+fesT7Iqsbki+vVtqlNO3t3qr6uXu0t7QRWgEbeQHWMpB5JH5V0weDXgsINDwBGLrPfVdDpvPr6kdVcVVcf3UtxwoTsQVfqnCle2aXVq90fn6mvT/rOd9yDrtGjpT/8Ib/+Xq2tTiuKw4ed727B2tKHl6q7t1tWVt293Vr68FJ6dQFZZA28rLWXu3xdEcbgAMRLXLujuzUQXbfO6XeV2mQ6kXB6ZaVLTZ+5BT9BHT58NDjZsyfYc+bPP3otL7vMmb5MJLw3w/YbX0+Pe7BXXe0eCKYvABip9B5dqZ8XP7iYZqmAj6ztJIwxYyRdKen9crJfkiSCL6Cy+LVHyHuz5QLxWkG4cePQBqLZenktWeKeOfKTno2qrw82vXnffU5gmBpzT48TWN19t/u1TN2Wao0RxOHD3oFgPnVfuUhlvyQx9QhkCDLVeLekP5H055L+n6STJO0t5qAAxI9fb6eoeQUSmUFKavrs7rudny+77GjmrrXVCYZyyXxlFpy3tw/Pqrnp6Ql+LdMzY7nwm0INo51F/8F+tW2KwYcDiBnPwMsYk8qGvc9a+/eS3rXWrpN0vqQ/C2NwAOKjEL2disUrkDBm+HSo27TkFVdIkyYNn/ZLJKRRHvMC48Y5j80M3o49Nv/X0d09dBrXbaypxQB+amq8p1BzXZ3oJ7NdRCaapQLD+WW8nh38nqoQeMcYM11SnaTjijoqxEpc63oQrmJmT0b6GWtvdw9IrHWmD9OP65a5O3DAyUJZ63zft8/Jiu3eLdXVuZ+zv//oc7q7nQDMGPctftJly4ilF8EvXz58rNZmD76OPdYJAltbj7at8KofG4lUuwgvNEsFhvNsJ2GMed5a22yM+UtJ/yapSdJaSeMl/b219p/CGiTtJKKTdc82VIxifRYKddwgmaDa2uz9ulJSG0z7tXKIUkODd71Xvns0BpbRg4MNsYGh8m0ncZwx5m8kHSvpcklzJN0h6RZJ4wo+SsRSnOt6EK58syfZslkj/Yyljh9Ef3/2ZqQpqSnUfPc7LKZUUOjVgNXaode62FlrmqUCwfllvH4n6U5Jbv+PtNbam4o5sHRkvKLj9b/9ov+PGmUhSDZrJJ8xt+MHkb5htpdEwvmebeowbOnXL9vrr611plrTV1BmHiMvhew6C5Qhv4xX1qnGoo4sIAKv6Hh11U79jxvwE+TzE/Qz5tYKIpf2CunHzfacmhontjhwILdjp6uuzr01RRDr1w8NmFLXxes1eY1jRH+HCbwAX/lONQaomEC5K/aqKJS3ICshg3zG3Fb3XXZZ7kFX6rh+eyQ2NDjF6bkEXZn1ZbW1znhHjx56+6hRwWrR/MaWmaVKtcjwOq5X8BeH1ahAJfILvFpCGwViq9irolDegqyEDPIZc6sDyzXZkn5cr2Bv/XrnvqDTi6nn3H338PHPmzd8jIcODQ/Ggsr2Hx6va+1V0xZGLy8ALqy1sf+aPXu2BVB61q+3trbWWicEcb5qa53bc2HM0GPk+tXQ4D62hgbn2A0Nzs9u4/U7pt/raGgY2ZiDnCv9NSQS1o4ePfxaL1vm/x64XYds1+rIgQC4krTVesQ0kQdVQb4IvFBpgvwyLBWFeC0jCWJGjw5+ziDnGT8+2LFGGiymvhIJ9+O7BYk1Nc7jM6+113sQJDB2ewyBF8Ky/sX1tuG2BmtuNLbhtga7/sXS+MfQL/DyLK6PE4rrUUnonTbcVVdJ3/52frXciYTTCDWzOH/+fGcvx/Ri/csuC36OVNF6Q8PwPR8l70UD+XAbUyEWvuS7+MGK4noUXyn3h8trVWOcEHihkrCSdKh8W0akW78++zFqa50tgPJpH5EKjKWjwd3EiYVrReH2z3QhWr0EOYbbYwi8EIbG2xvV3Tv8H8OGugZ1fakr/AHlIN9VjQAiEOc9EaPgVlgvORmnVDF7queWm+pq72OkS92fyybZ6c9dvPjoSktrnaDLa5/HXHi9tkJs4RTkGBThIypee32W+h6gBF5AzBRzT8RS5BVwHj7sfHV1SatXez9/YCB40Lpnj5O5CtrdPlNmAujQISdwSq14TCT8g8RMNTXer60QrV6CHMPtMUAYvPb6LPU9QAm8gJihd9pQQVtSeAU0DQ3Bg9aJE53sWCEbn+7Z4wSHhw87tWa7d/v3EUtpaJC+9z3vur5CtHoJcgy3xwBhaG9pV23N0H8Ma2tq1d5S4v8YelXdx+mLVY2oNOW0qnGksq28W7/eWcnntiIw9bigbSKqqwuzEjGzFUSQ15TtOflct6J9hljViJCU46rGyIOqIF8EXkBl82uHUFPjHrwkEsPbIhQjsPL78utZ5hUw5tPnzO3Yheif5onAC/DlF3gx1QggMsmks4qzqsr5nky6Py61LU6qpis1FdbWJh086H38trajx5aczaKLXa+U2ron29Rfa6sz7bh+feF3hnBbTNDf79wOIFq0kwAQiUL0K/Nqh+AmveXDkiXF2cDaq6dX2ArRasIXm2QDvmgnASB2CpGVyWWlZ6rlw+LF0pgxw/dMHD3aWUWYTVXGv5o1NU5h/0g2vy40VsYC8UXgBSAS+fQry5yanD8/WLCU6d13pQMHjv6cSEjf/a6zijDbqr3Dh48GWqnvPT1O8qe728nieU2ZhoWVsUB8EXgBiIRfVsat9is1NZlqUNrd7dRs/eVfjnws+/Y531O1ZOvX+z9+/HgnABs/fmgAJxW+lipoHVy6QrSaAFAcRavxMsacLOlfJB0vyUrqsNauNsZMlHSvpEZJXZL+l7X2937HosYLKD9eNV5LljgBVebtXtv5pPZMHKnUlkxB9oVM1Ur5TS8W4p/W2O7bSY0X4CuqGq9Dkv7WWnuapDMlfd4Yc5qklZI2WWtPlbRp8GcAFcYrK7Nxo3vtl9e+h4Uqkt+50wl0gmzGncrW+XW4L8R0I6sTgfIT2qpGY8wPJH1r8Osca+3vjDHvkfSktXaK33OLnvG6J0ZVsQAQd6lsGxkvwFXkqxqNMY2STpf0n5KOt9b+bvCu/5YzFen2nKXGmK3GmK1vv/12GMMEAAAoLq/OqoX6kjRe0nOSLhn8+Z2M+3+f7Rh0rgeiVahO6EG2sQm6vY/XVyKR23HSO9w3NAQ/T2r8o0d7P8aY3LfuyTaGgnagzxed6wFfiqpzvTGmRtK/SUpaax8cvHnX4BSjBr+/VcwxABi5QtQaua1KTG+9kFq9d9llTiH9+PH5jbWnR5o0SVq+fPiY3ezefbRQ3a0Ng5dU2wu/2baJE/1fs99x3bA6ESh9xVzVaCStk7THWvultNu/LqnHWnuzMWalpInW2mv9jsWqRiBaheiE3tjoBB6ZUt3eM1fvhSXzdSWTTkDZ3e28bq/Xl+r35faaJP+VmKkVlG4mTcr9OaFjVSPgK6oar3mSLpP0UWNM5+DXfEk3SzrXGPOqpI8N/gwgxgrRCd2vYapbRi0MVVXDs0+trUczX15BlzHOY/yyUx0d0p497vd5PS+ZlPbuHX57TQ3NT4FywV6NALIqRD8pv4zXzp3BkyfGOAFfX593i4lcuL0Or7Gms9b/NXV1Zb8/k9fjEwlnSjQ2yHgBviJf1QigtBWiE7rfNjZBM2eJhJOF6uqSVq8evt9iPtxq1fwyWdLRacZsW/PkunWP13m9MmcASg+BF4BAUtvppAKfXAu8/YK3oEXtf/jD0anB1lZnf8VEItdXMlxmwOMXCKYHTtkC0mz3Z24HNHGi+znZ3BooI17LHeP0RTsJoPxltl0YN867jYPb4/NtP5F+zPSxuLWiSG89kW382Vo+uJ1j9Ghra2qGt6RIb18RC7STAHzJp50ENV4AYslvJeXddxduFaRXrVpqdePOnU7Gqb3dO8uXTw2cXz3X+PHOfcYMvQax2KdRosYLyIIaLwCxlTndlppK9FtJWahVkNXVIw+6pOx9ztxeo189V1eXMy2ZGdewTyNQ+sh4AYiMX6ZI8r7vsstGnmzxy3Tlmr3KNTvn1+Orulpat877NebSO61oyHgBvsh4AYglv0yRX2H6SIvN/VZleo1p+fLhWatUJssr/vDKzqV+dltQMDDgBGoU2ucuuS2pxtsbVbWqSo23Nyq5zWeLACAiZLwARCbfjvheWam5c6UnnvBPxGTrAO81pkyjRzuPO3jQ/f6RZucSCWnfvpH1TiuaGGa8ktuSWvrwUvUfPHrBamtq1XFBh1qbor5gqDRkvABExquGS8q/I75XNuzxx52pvVSfrVR8kJLeCiLX2rJMBw54B12FyM7t2TPy3mmVpG1T25CgS5L6D/arbRNFcYgXAi8ARZNtY+xcG4ymy+wrJh3dZFuS1q93grD0Pl9jx2YfVy4bZbsxZmifs3yPV18/8t5plWRnr/tqBa/bgagQeAEommyr/QrREV+SrrrKCbgyA6mnn3am61J6epzbly/PrbYslyatmRmuzOMFETT4xFH1de6pRa/bgagQeAEoGr+NsVO8MlduU5Nukknp2992b73Q0eEeYHnt8ZgaV+aYVq8enrUaPdrZvDqdV8CUfrzUNGim6mqmFEeivaVdtTVD36Tamlq1txDBIl4IvAAUTa41XNmmJt20tXnXeA8MFGa8blmw735X+t73cs/WeU2vrlvHlOJItDa1quOCDjXUNcjIqKGugcJ6xBKrGgEUTa49sby6uaevRMxsbur2+JTqavfgK+oVg7k2aI2dGK5qBOKEVY0AIpFrDVe2qUm3jJhX3ZQxzmPdskurV0e7YjB96rG93QnCMqdW/VaDAihhXps4xumLTbKB8uO2qbTXZtepTayDboZtjLXLlnmfx28MYXLbKLu21hl75u01Nc4m3VGNdQg2yQZ8iU2yAcSJ1xTkkiVOrZPXFKBfc9NEwul9FXTqLp+tgQrNa2rVa4o0XaTNVJlqBHwx1QhUmLhPU3m1mbjvvqFTh1VVTjCWCi78mpGOH59bcXq2Vhdh8JpaDbIogA2zgdJE4AXEVL7BUz4rA8PmFXD09Ejvvnv058OHpbvuGtpwNddj5vr4XI8zEl6BZHV1sOeHOVYAhUHgBcTQSIKnOGRyssllG50DB4Y2XPVqZprtmJmBbBw2ofZqLeG2KMANG2YDpYfAC4ihkQRPccjkZJPrNjrpY3drZpqt07tbIPuHPzhNUHM5TqF5rfpcs2bo7YlE9GMFUBgEXkAMjSR4ynfj6TDlui1P+tjz2WbILZA9eFCaMCH6Tai99mNMv333bqdha9RjBTByBF5ADI0keBrJxtP5yKcWza2B6OrVw7fgkZx6p76+ocfPdfNor4B1z57S2YSaDbOB8kDgBcTQSIKnQm08HUSutWjJpDRpkrR48fDnSM4WPOmZr3HjnMCrp2dkCwVKIQuYKe4rUwHkyavBV5y+aKCKSpTe3DORiFHzzDSJhH/D03RuzUKzPSdbQ9WgvBqVxuU6ZhrJeENpCksDVcCXaKAKlK44NPr0Gtfixe73GeNMiaXzahbq9xyvhqluj82mlPZHDLJnpZvQPis0UAV8+TVQJfACYi7fX8LF5hdIuY3Nr+u813Pi+tqDyAz05s+XNm50fk61svDqtJ9vwBna9SLwAnzRuR4oYXFtD+F3frdaNL96Kq/6tfnz3R/vdXu+Cl1P5Vb7duedR3/u6fGvW8u3Ji2unxUARxF4ATHh9cs/roXhXudPJNyntbx6dyUS3lNhGze6n8Pr9nzks0AgW5Dm1r7CT2aPtnwXV8T1swIgjVfxV5y+KK5HufMrpo5rYXg+48q18NsY9+J6Ywr3OnIp4A/6mr3G7feV+ZryKZIP7bNCcT3gSz7F9WS8gBjw61Sfag+R3mZh7NhwxycNz/RIubetyLUXVRgZnFym54LuKJDP+DKfk0/frjBbiQDID4EXEANBfvnv23f0zz094W587TUdJ+Xf1DPIlF0YzWBzCe6CBmm5bolUyNdEo1Ug3gi8gBjI9ss/6o2vC33+oHVVYWRwcgnuggZpmeP2E+Q1hdVMlaatQAi85iDj9EWNF8pdttqcMGqd/BT6/IVqjFooQeup8q2hGsnrzfWc+TZQzek81HgBvkSNF+KK/2Ef7ffU3+9sjyMNz4JEvVqt0OePW9sDv+m59M9oW5u0ZEnu9XYjmTLNJduY6wrNfM8DYAS8IrI4fZHxKk9xXa0XpqDXIOprVegtbOKW8fLi9rpraqwdPTr3a5FvJiqXbONIrmtOWU0yXoAv+WS8Ig+qgnwReJWnUvnlW0y5tjIo+h58PgrZ3mDZsnACyZFMu3m9N15fxfrc5vIZGcmUcE5/Hwm8AF9+gRdTjYhM3KabopDLNSjF1Wpe01cbNxa2aN5tyjrfabf05+WiWJ/boNOUyaTz+t2kTwlnXqurrjq61VDmQoBCryAFIDJeiA4Zr9K5BvlONYaxKMBrbImE+7mrq/3HnWumK4z3LFvmzu0auL1Pfo9Lf29Sr8fzOpHxAnyJqUbEUdR1S3EQ9TUIOhWXb4AYRmCZT6Dkd43z6Tqf63tW6Gljr2uQGWQGvVZZ3x8CL8AXgRdiK+q6pTiI6hrkEvTlm7kKI7DMJ1DyCy7yCeRyDboyr0mgLFMe1yDz/Ql6rbJmJAm8AF9+gZdx7o+3OXPm2K1bt0Y9DKCspOp6MjU0ODVk+T42U6pdxs6dTq1RqmYo87Z867u8xpZION3+vTarNsapl3Mb79KlQ59XW+u0jejpGf74INcgyHjTz5VrvVvQ9yfbub2eN0yqGKwEfn8AUTDGPGetneN2H8X1QIXKpbB/JH2oMhcFSPn3mnLjtz3PkiVHe6Nl8upB5tUtf/XqwmxflK0IP5/eWUHfnyBbGVFQDxSZVyosTl9MNQKFl2v9VaGmRItR97V+vXsxfaFbVxTiGgSZysxn8UEu3ffTH7dsWR6vialGwJeYagSQyWtKbaR7IbpNLaYfr6rKfYbKa+ovKL/ptvb2wk1tjpTbdc+U6/Rl6JhqBHz5TTWOCnswAOIhFXgUMiDJDCpS04jp56uvdw+QRrr9kd/UaWtrfPqepcaxZIk0MDD8fmOY6gPKGRkvAAUTpMi7WJm2kSwAiIJX5k8qgUQSGS/AF8X1iC02yS4vQQr2vYrXR5qRymcBQJSfv4kT3W9P34AbQPkh8EJk8t3SpdyUU/DpNV2YeXsxtj/KNaCL6+dv//7y+TwAGI6pRkSm1KaGiqFY025RcXs9NTXSscdKe/ZEX9ieLurPn99UY7pYfh6YagR8MdWIWGKTbO9NpHPt41RsQbNymVmnRML53tMTr6ySFP3nL+higjh+HgDkj8ALkQk6LVXOov7lH0SuU3KpacS775beeUc6cGDo/XEJJKL+/AVpZpoSp88DgJEh8EJkRtINvVxE/cs/iHyycqlgza1dghSPQCLqz59bTZpXYX2cPg8ARobAC5Ep1uq2UhL1L/8g8snKuQVr6eIQSIzk81eoBRGZiwwKtS0RgPiiuB6IWLZO71HLpwjdr3A8lsXiOXBbQGCM9Nd/La1ZU5jjx/nzIInieiALv+J6Ai8AvvJZeekVrFVXS+vWxTCQyIHXazPGqWsr5dcWGIEX4ItVjQDyls+UnNcUaqkHXZL3FKu18Vg0ACDeCLyAHJRTs9Nc5NrwtNj1e1G+D371aXFYNAAg3gi8gIDi2uk8rorRnV6K/n1obz8605YpDosGwpTcllTj7Y2qWlWlxtsbldzGXwYgGwIvIKBSaXZa7rzehyVLwgm+WludQnq34Kuvr7IC8aUPL1V3b7esrLp7u7X04aUEX0AWRQu8jDHfNca8ZYx5Ke22icaYx4wxrw5+/+NinR8otFJodloJvK73wEB4ma81a5xC+sy+Wz09lZUF7T/YP+zntk38TwTwU8yM11pJ52XctlLSJmvtqZI2Df4MlIRSaHZaCfyud5gZyNZWafz4aMcQRzt7+Z8I4KdogZe19ilJezJuvkjSusE/r5P0yWKdHyi0Umh2WgmybbUTZgaSLOhw9XX8TwTwE3aN1/HW2t8N/vm/JR3v9UBjzFJjzFZjzNa33347nNEBPui0Hw+p96G62v3+MDOQlZ4Fra2pHfZzewv/EwH8RFZcb53OrZ7d96y1HdbaOdbaOZMnTw5xZIC3Yq3UQ25aW52eYFFnIPPNgpZLW5KOCzrUUNcgI6OGugZ1XNCh1ib+UgB+RoV8vl3GmPdYa39njHmPpLdCPj+AMpEKeqPcXiefMWTuBJBqh5F+vFLR2tRKoAXkqKhbBhljGiX90Fo7ffDnr0vqsdbebIxZKWmitfbabMdhyyAA5SKfvS9jhy2DAF+RbBlkjPm+pGckTTHGvGGMuVLSzZLONca8Kuljgz8DQMWgIB+obEWbarTWLvK4q6VY5wSAuKuvd894VUpBPlDp6FyPslIuRcsoX7QlASobgRfKRtR7+AFB0JYEqGwEXigb7KVYfkaawYxrBjSObUnieq2AckPghbJB0XJhRf2LON8MZmrcxkiXXUYGNAiyxUB4CLxQNiq1i3gxAqQ4/CLOJ4OZPm5peLcDMqDuyBYD4SlqH69CoY8XgshsTCk5RcvlXD9TrNcch15TVVXubaKMcabo3HiNO+jzK1XO15o+XoCvSPp4AWGrxKLlYmUq4jBtm08GM8j4yj0Dmo9KzRYDUSDwQlmJY9FyMRUrQIrDL+J82i5kGx9tG9zR4gIID4EXUMKKFSDF4RdxPhlMt3GnZsUqIQOar0rMFgNRIfACYs6veL5YAVJcfhHnmsF0G/fddzulSJWQAc1V+merrc353FRKthiICsX1QIwFKZ5PJp1fmjt3Opmu9nZ+aSK7ES3MoLge8EVxPVCighTPj7SuLep+XZUi23UO+32ghQQQjaJtkg1g5Iq9ujAz65Hq1yWRNSukbNc5ivchDitXgUrEVCMQY8XupxWHfl2VINt1juJ9GNE5mWoEfDHVCJSoYq8uJOsRjmzXOYr3IQ4rV4FKROAFxFixVxfGoV9XJch2naN4H+KychWoNAReQMwVsyksWY9wZLvOUb0PldZwGIgDAi+ggpVD1qMUVmVmu87l8D4ACIbiegAlqxI3Ro8FiusBXxTXAyhL9KICUGoIvACULFZlAig1BF4ASharMgGUGgIvACUrn9WApVCMD6B8EXgBKFm5rgZMFeN3dzt14amteQi+AISFVY0AKgZbJBUIqxoBX6xqBABRjA8gegReAGIhjNorivEBRI3AC0Dkwqq9YoskAFEj8AIQubAaobI1D4CoUVwPIHJVVe512sY4GzgjZiiuB3xRXA8g1qi9AlApCLwARI7aKwCVgsALQOSovQJQKUZFPQAAkJwgi0ALQLkj4wUAABASAi8AAICQEHgBAACEhMALAAAgJAReAAAAISHwAgAACAmBFwAAQEgIvAAAAEJC4AUAABASAi8AAICQEHgBAACEhMALAAAgJAReAAAAISHwAgAACAmBFwAAQEgIvAAAAEJC4AUAABASAi8AAICQEHgBAACEhMALAAAgJAReAAAAISHwAgAACAmBFwAAQEgIvAAAAEJC4AUAABASAi8AAICQRBJ4GWPOM8b8yhjzmjFmZRRjAAAACFvogZcxplrSHZI+Iek0SYuMMaeFPQ4AAICwRZHxOkPSa9baX1trD0j6V0kXRTAOAACAUEUReJ0o6TdpP78xeBsAAEBZi21xvTFmqTFmqzFm69tvvx31cAAAAEYsisDrTUknp/180uBtQ1hrO6y1c6y1cyZPnhza4AAAWVjrfAHIWRSB188lnWqMOcUYM1rSpyU9FME4AAAAQjUq7BNaaw8ZY74g6T8kVUv6rrX2l2GPAwAAIGyhB16SZK3dKGljFOcGAACISmyL6wEAAMoNgRcAAEBICLwAAABCQuAFAAAQEgIvAACAkBB4AQAAhITACwAAICQEXgAAACEh8AIAAAgJgRcAAEBICLwAAABCQuAFAAAQEmOtjXoMWRlj3pbUXeTTTJK0u8jnqDRc08LiehYe17SwuJ6FxzUtrLCuZ4O1drLbHSUReIXBGLPVWjsn6nGUE65pYXE9C49rWlhcz8LjmhZWHK4nU40AAAAhIfACAAAICYHXUR1RD6AMcU0Li+tZeFzTwuJ6Fh7XtLAiv57UeAEAAISEjBcAAEBICLwAAABCUvGBlzFmjDHmWWPMC8aYXxpjVkU9pnJgjKk2xvzCGPPDqMdSDowxXcaYbcaYTmPM1qjHU+qMMX9kjHnAGLPDGPOyMWZu1GMqZcaYKYOfzdTXH4wxX4p6XKXMGPPlwd9JLxljvm+MGRP1mEqdMWb54PX8ZZSfz4qv8TLGGEnjrLV9xpgaSVskLbfW/izioZU0Y8zfSJoj6Vhr7YKox1PqjDFdkuZYa2mkWADGmHWSfmKt/Y4xZrSkWmvtOxEPqywYY6olvSnpz6y1xW58XZaMMSfK+V10mrV2nzHmPkkbrbVrox1Z6TLGTJf0r5LOkHRA0iOS/tpa+1rYY6n4jJd19A3+WDP4VdnR6AgZY06SdL6k70Q9FiCTMaZO0tmS7pIka+0Bgq6CapH0OkHXiI2SNNYYM0pSraTfRjyeUjdN0n9aa/uttYck/T9Jl0QxkIoPvKQj02Kdkt6S9Ji19j8jHlKpu13StZIORzyOcmIlPWqMec4YszTqwZS4UyS9Lel7g9Ph3zHGjIt6UGXk05K+H/UgSpm19k1J35C0U9LvJPVaax+NdlQl7yVJHzLGJIwxtZLmSzo5ioEQeEmy1g5Ya2dJOknSGYMpSeTBGLNA0lvW2ueiHkuZOcta2yzpE5I+b4w5O+oBlbBRkpol3WmtPV3Su5JWRjuk8jA4bXuhpPujHkspM8b8saSL5Pwn4QRJ44wxi6MdVWmz1r4s6RZJj8qZZuyUNBDFWAi80gxON2yWdF7EQyll8yRdOFiT9K+SPmqMWR/tkErf4P+AZa19S9IGOXUKyM8bkt5Iy2w/ICcQw8h9QtLz1tpdUQ+kxH1M0n9Za9+21h6U9KCkD0Y8ppJnrb3LWjvbWnu2pN9LeiWKcVR84GWMmWyM+aPBP4+VdK6kHZEOqoRZa79irT3JWtsoZ8rhCWst/1MbAWPMOGPMhNSfJX1cTtocebDW/rek3xhjpgze1CJpe4RDKieLxDRjIeyUdKYxpnZwAViLpJcjHlPJM8YcN/i9Xk591z1RjGNUFCeNmfdIWje4EqdK0n3WWlogIE6Ol7TB+fdXoyTdY619JNohlbwvSkoOTo39WtLlEY+n5A3+p+BcSZ+Leiylzlr7n8aYByQ9L+mQpF8oBlvdlIF/M8YkJB2U9PmoFtVUfDsJAACAsFT8VCMAAEBYCLwAAABCQuAFAAAQEgIvAACAkBB4AQAAhITAC0BZM8YMGGM6jTEvGWMeTuvb12iMscaYr6Y9dpIx5qAx5luRDRhAWSPwAlDu9llrZ1lrp0vaI+nzaff9l5wN3VM+JemXYQ4OQGUh8AJQSZ6RdGLaz/2SXjbGzBn8+VJJ94U+KgAVg8ALQEUY3J2iRdJDGXf9q6RPG2NOlrNp7m/DHhuAykHgBaDcjTXGdEr6bznbLz2Wcf8jcra6+bSke8MdGoBKQ+AFoNzts9bOktQgyWhojZestQckPSfpbyU9EProAFQUAi8AFcFa2y/pakl/a4wZlXH3/5V0nbV2T/gjA1BJCLwAVAxr7S8kvShpUcbtv7TWrotmVAAqibHWRj0GAACAikDGCwAAICQEXgAAACEh8AIAAAgJgRcAAEBICLwAAABCQuAFAAAQEgIvAACAkPz/eg0EN+YUWooAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.lines as mlines\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "column = model.tree_.column\n",
    "threshold =  model.tree_.threshold\n",
    "\n",
    "X_left = X_train[X_train[:,column] <= threshold]\n",
    "X_right = X_train[X_train[:,column] > threshold]\n",
    "        \n",
    "y_left = y_train[X_train[:,column] <= threshold]\n",
    "y_right = y_train[X_train[:,column] > threshold]\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.scatter(X_left[:,column], y_left, color=\"blue\", label=\"left class\")\n",
    "plt.scatter(X_right[:,column], y_right, color=\"green\", label=\"right class\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.xlabel(boston['feature_names'][model.tree_.column])\n",
    "plt.plot([3, model.tree_.threshold], [model.tree_.left.prediction, model.tree_.left.prediction],\n",
    "         'k-', lw=2, color='orange', label=\"prediction left\")\n",
    "plt.plot([model.tree_.threshold, 9], [model.tree_.right.prediction, model.tree_.right.prediction],\n",
    "         'k-', lw=2, color='purple', label=\"prediction right\")\n",
    "plt.plot([model.tree_.threshold, model.tree_.threshold], [0, 50], 'k-', lw=2, color='red', label=\"threshold\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 <a id=\"task5\"></a>  (0.5 points)\n",
    "\n",
    "Keep working with boston dataset. \n",
    "- Use `GridSearchCV` to find the best hyperparameters (`max_depth` and `min_samples_split`) on 5-Fold cross-validation\n",
    "- Train the model with the best set of hyperparameters on the whole train dataset. \n",
    "- Report `RMSE` on test dataset and hyperparameters of the best estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 182 candidates, totalling 910 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'min_samples_split': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth' : range(2, 15), 'min_samples_split' : range(1, 15)}\n",
    "model = MyDecisionTreeRegressor()\n",
    "clf = GridSearchCV(model, parameters, verbose=10, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4012885682725"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = MyDecisionTreeRegressor(max_depth=clf.best_params_['max_depth'],\n",
    "                                min_samples_split=clf.best_params_['min_samples_split'])\n",
    "model.fit(X_train, y_train)\n",
    "result = model.predict(X_test)\n",
    "mean_squared_error(y_test, result, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 <a id=\"task6\"></a>  (2 points)\n",
    "\n",
    "Recall definition of bias and variance:\n",
    "$$\n",
    "\\text{Bias}^2 = \\mathbb{E}_{p(x, y)} \\left[  (f(x) - \\mathbb{E}_{\\mathbb{X}}a_{\\mathbb{X}}(x))^2 \\right] \\\\\n",
    "\\text{Variance} = \\mathbb{E}_{p(x, y)} \\left[  \\mathbb{V}_{\\mathbb{X}}( a_{\\mathbb{X}}(x))  \\right]\n",
    "$$\n",
    "\n",
    "We wil now use use the following algorithm to estimate bias and variance:\n",
    "\n",
    "1. Use bootsrap to create `n_iter` samples from the original dataset: $X_1, \\dots, X_{n\\_iter}$\n",
    "2. For each bootstrapped sample define out-of-bag (OOB) sample $Z_1, \\dots, Z_{n_iter}$, which contain all the observations, which did not appear in the corresponding boostraped sample\n",
    "3. Fit the model on $X_i$s and compute predictions on $Z_i$s\n",
    "4. For a given *object* $n$:\n",
    "     - bias^2: squared difference between true value $y_n$ and average prediction (average over the algorithms, for which $n$ was in OOB)\n",
    "     - variance: variance of the prediction (predictions of the algorithms, for which $n$ was in OOB)\n",
    "5. Average bias^2 and variance over all the points\n",
    "    \n",
    "**Implement `get_bias_variance` function, using the algorithm above**\n",
    "\n",
    "*Note:*  You can only use 1 loop (for bootsrap iterations). All other operations should be vectorized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_bias_variance(estimator, x, y, n_iter):\n",
    "    \"\"\" \n",
    "    Calculate bias and variance of the `estimator`. Using a given dataset and bootstrap with `n_iter` samples. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray, shape (n_samples, n_features)\n",
    "        The input samples.\n",
    "    y : ndarray, shape (n_samples, n_features)\n",
    "        The input samples.\n",
    "    n_iter: int\n",
    "        Number of samples in \n",
    "    Returns\n",
    "    -------\n",
    "    bias2 : float, \n",
    "        Estiamted squared bias\n",
    "    variance : float, \n",
    "        Estiamted variance\n",
    "    \"\"\"\n",
    "    \n",
    "    variance = np.array([])\n",
    "    bias2 = np.array([])\n",
    "    prediction_matrix = np.empty((len(x), 1))\n",
    "    prediction_matrix[:] = np.nan\n",
    "    \n",
    "    for i in tqdm(range(n_iter)):\n",
    "        boost_indexes = np.random.randint(len(x), size=len(x))\n",
    "        boost_x = x[boost_indexes]\n",
    "        boost_y = y[boost_indexes]\n",
    "        \n",
    "        OOB_indexes = np.setdiff1d(np.array(range(len(x))), boost_indexes)\n",
    "        OOB_x = x[OOB_indexes]\n",
    "        OOB_y = y[OOB_indexes]\n",
    "        \n",
    "        estimator.fit(boost_x, boost_y)\n",
    "        prediction = estimator.predict(OOB_x)\n",
    "        \n",
    "        tmp = np.empty(len(x))\n",
    "        tmp[:] = np.NaN\n",
    "        np.put(tmp, OOB_indexes, prediction)\n",
    "        \n",
    "        prediction_matrix = np.column_stack((prediction_matrix, tmp))\n",
    "        \n",
    "    \n",
    "    prediction_matrix = np.delete(prediction_matrix, 1, axis=1)\n",
    "    \n",
    "    variance = np.nanvar(prediction_matrix, axis=1)\n",
    "    bias2 = np.square(y - np.nanmean(prediction_matrix, axis=1))\n",
    "    \n",
    "    return np.nanmean(bias2), np.nanmean(variance)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:08<00:00,  2.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18.428249158680412, 10.340433293037712)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "estimator = MyDecisionTreeRegressor(max_depth=8, min_samples_split=15)\n",
    "\n",
    "get_bias_variance(estimator, X_train, y_train, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 <a id=\"task7\"></a>  (0.5 points)\n",
    "\n",
    "Compute bias and variance for the trees of different depths. Plot how bias and variance change as depth increases. \n",
    "\n",
    "Comment on what you observe, how does your result correspond to what we have discussed in class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:01<00:00, 17.89it/s]\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.02it/s]\n",
      "100%|██████████| 25/25 [00:04<00:00,  5.93it/s]\n",
      "100%|██████████| 25/25 [00:05<00:00,  4.50it/s]\n",
      "100%|██████████| 25/25 [00:06<00:00,  3.57it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.98it/s]\n",
      "100%|██████████| 25/25 [00:09<00:00,  2.57it/s]\n",
      "100%|██████████| 25/25 [00:11<00:00,  2.22it/s]\n",
      "100%|██████████| 25/25 [00:11<00:00,  2.08it/s]\n",
      "100%|██████████| 25/25 [00:12<00:00,  1.95it/s]\n",
      "100%|██████████| 25/25 [00:13<00:00,  1.86it/s]\n",
      "100%|██████████| 25/25 [00:13<00:00,  1.81it/s]\n",
      "100%|██████████| 25/25 [00:14<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "values_bias = np.array([])\n",
    "values_variance = np.array([])\n",
    "depth_range = range(2, 15)\n",
    "\n",
    "for depth in depth_range:\n",
    "    model = MyDecisionTreeRegressor(max_depth=depth, min_samples_split=4)\n",
    "    bias, variance = get_bias_variance(model, X_train, y_train, 25)\n",
    "    values_bias = np.append(values_bias, [bias])\n",
    "    values_variance = np.append(values_variance, [variance])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(depth_range, values_bias, color='green', label='bias2')\n",
    "plt.plot(depth_range, values_variance, color='blue', label='variance')\n",
    "plt.plot(depth_range, values_bias + values_variance, color='red', label='Error')\n",
    "plt.xlabel('depth')\n",
    "plt.ylabel('value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "As we say in class high variance usually means that model is overfitted and high bias usually means that model is underfitted. As we can see from the graph, as the depth increases, the bias decreases and the variance increases. At depth 6, the minimum error is reached, which corresponds to the result of GridSearch optimal depth. Further the situation worsens, apparently due to overtraining, such conclusion can be made by the increasing variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 <a id=\"task8\"></a>  (0.5 points)\n",
    "\n",
    "Let's try to reduce variance with bagging. Use `sklearn.ensemble.BaggingRegressor` to get an ensemble and compute its bias and variance. \n",
    "\n",
    "Answer the following questions:\n",
    " - How bagging should affect bias and variance in theory?\n",
    " - How bias and variance change (if they change) compared to an individual tree in you experiments? \n",
    " - Do your results align with the theory? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=MyDecisionTreeRegressor(max_depth=8,\n",
       "                                                        min_samples_split=15),\n",
       "                 n_estimators=100, n_jobs=-1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "model = BaggingRegressor(base_estimator=MyDecisionTreeRegressor(max_depth=8, min_samples_split=15), n_jobs=-1, n_estimators=100)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 3.366156397356335\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(X_test)\n",
    "print('RMSE =', mean_squared_error(y_test, result, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:54<00:00,  2.74s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16.59554739601765, 2.1733093024133425)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bias_variance(model, X_train, y_train, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "In theory, this method should reduce the variance without affecting the bias. In the experiment we obtained results confirming the theory. We can notice that the bias measurements are practically unchanged, while the variance has become much smaller. This is achieved by using bootstrap for fitting several models and than aggregate their individual predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. More Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will be working with [Thyroid Disease Data Set](https://archive.ics.uci.edu/ml/datasets/thyroid+disease) to solve a classification task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>41.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on_thyroxine</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_on_thyroxine</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on_antithyroid_medication</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sick</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pregnant</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thyroid_surgery</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I131_treatment</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_hypothyroid</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_hyperthyroid</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lithium</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goitre</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tumor</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypopituitary</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psych</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSH_measured</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSH</th>\n",
       "      <td>1.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T3_measured</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T3</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TT4_measured</th>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TT4</th>\n",
       "      <td>125.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T4U_measured</th>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T4U</th>\n",
       "      <td>1.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTI_measured</th>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTI</th>\n",
       "      <td>109.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBG_measured</th>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBG</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>referral_source</th>\n",
       "      <td>SVHC</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>SVI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0      1      2      3     4\n",
       "age                         41.0   23.0   46.0   70.0  70.0\n",
       "sex                            F      F      M      F     F\n",
       "on_thyroxine                   f      f      f      t     f\n",
       "query_on_thyroxine             f      f      f      f     f\n",
       "on_antithyroid_medication      f      f      f      f     f\n",
       "sick                           f      f      f      f     f\n",
       "pregnant                       f      f      f      f     f\n",
       "thyroid_surgery                f      f      f      f     f\n",
       "I131_treatment                 f      f      f      f     f\n",
       "query_hypothyroid              f      f      f      f     f\n",
       "query_hyperthyroid             f      f      f      f     f\n",
       "lithium                        f      f      f      f     f\n",
       "goitre                         f      f      f      f     f\n",
       "tumor                          f      f      f      f     f\n",
       "hypopituitary                  f      f      f      f     f\n",
       "psych                          f      f      f      f     f\n",
       "TSH_measured                   t      t      t      t     t\n",
       "TSH                          1.3    4.1   0.98   0.16  0.72\n",
       "T3_measured                    t      t      f      t     t\n",
       "T3                           2.5    2.0    NaN    1.9   1.2\n",
       "TT4_measured                   t      t      t      t     t\n",
       "TT4                        125.0  102.0  109.0  175.0  61.0\n",
       "T4U_measured                   t      f      t      f     t\n",
       "T4U                         1.14    NaN   0.91    NaN  0.87\n",
       "FTI_measured                   t      f      t      f     t\n",
       "FTI                        109.0    NaN  120.0    NaN  70.0\n",
       "TBG_measured                   f      f      f      f     f\n",
       "TBG                          NaN    NaN    NaN    NaN   NaN\n",
       "referral_source             SVHC  other  other  other   SVI"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('thyroid_disease.csv')\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Class'])\n",
    "X = df.drop('Class', axis=1)\n",
    "X.head(5).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 <a id=\"task2_1\"></a> (1 point)\n",
    "\n",
    "Let's start with data preprocessing. \n",
    "\n",
    "0. Drop columns, which are not usefull (e.g. a lot of missing values). Motivate your choice. \n",
    "1. Split dataset into train and test\n",
    "2. You've probably noticed that we have both categorical and numerical columns. Here is what you need to do with them:\n",
    "    - Categorical: Fill missing values and apply one-hot-encoding\n",
    "    - Numeric: Fill missing values\n",
    "    \n",
    "Use `ColumnTranformer` to define a single transformer for all the columns in the dataset. It takes as input a list of tuples\n",
    "\n",
    "```\n",
    "ColumnTransformer([\n",
    "    ('name1', transorm1, column_names1),\n",
    "    ('name2', transorm2, column_names2)\n",
    "])\n",
    "```\n",
    "\n",
    "Pay attention to an argument `remainder='passthrough'`. [Here](https://scikit-learn.org/stable/modules/compose.html#column-transformer) you can find some examples of how to use column transformer. \n",
    "    \n",
    "Since we want to apply 2 transformations to categorical feature, it is very convenient to combine them into a `Pipeline`:\n",
    "\n",
    "```\n",
    "double_tranform = make_pipeline(\n",
    "                        transform_1,\n",
    "                        transform_2\n",
    "                        )\n",
    "```\n",
    "\n",
    "P.S. Choose your favourite way to fill missing values. \n",
    "\n",
    "*Hint* Categorical column usually have `dtype = 'object'`. This may help to obtain list of categorical and numerical columns on the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3772 entries, 0 to 3771\n",
      "Data columns (total 29 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   age                        3771 non-null   float64\n",
      " 1   sex                        3622 non-null   object \n",
      " 2   on_thyroxine               3772 non-null   object \n",
      " 3   query_on_thyroxine         3772 non-null   object \n",
      " 4   on_antithyroid_medication  3772 non-null   object \n",
      " 5   sick                       3772 non-null   object \n",
      " 6   pregnant                   3772 non-null   object \n",
      " 7   thyroid_surgery            3772 non-null   object \n",
      " 8   I131_treatment             3772 non-null   object \n",
      " 9   query_hypothyroid          3772 non-null   object \n",
      " 10  query_hyperthyroid         3772 non-null   object \n",
      " 11  lithium                    3772 non-null   object \n",
      " 12  goitre                     3772 non-null   object \n",
      " 13  tumor                      3772 non-null   object \n",
      " 14  hypopituitary              3772 non-null   object \n",
      " 15  psych                      3772 non-null   object \n",
      " 16  TSH_measured               3772 non-null   object \n",
      " 17  TSH                        3403 non-null   float64\n",
      " 18  T3_measured                3772 non-null   object \n",
      " 19  T3                         3003 non-null   float64\n",
      " 20  TT4_measured               3772 non-null   object \n",
      " 21  TT4                        3541 non-null   float64\n",
      " 22  T4U_measured               3772 non-null   object \n",
      " 23  T4U                        3385 non-null   float64\n",
      " 24  FTI_measured               3772 non-null   object \n",
      " 25  FTI                        3387 non-null   float64\n",
      " 26  TBG_measured               3772 non-null   object \n",
      " 27  TBG                        0 non-null      float64\n",
      " 28  referral_source            3772 non-null   object \n",
      "dtypes: float64(7), object(22)\n",
      "memory usage: 854.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>TSH</th>\n",
       "      <th>T3</th>\n",
       "      <th>TT4</th>\n",
       "      <th>T4U</th>\n",
       "      <th>FTI</th>\n",
       "      <th>TBG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3771.000000</td>\n",
       "      <td>3403.000000</td>\n",
       "      <td>3003.000000</td>\n",
       "      <td>3541.000000</td>\n",
       "      <td>3385.000000</td>\n",
       "      <td>3387.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.735879</td>\n",
       "      <td>5.086766</td>\n",
       "      <td>2.013500</td>\n",
       "      <td>108.319345</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>110.469649</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.084958</td>\n",
       "      <td>24.521470</td>\n",
       "      <td>0.827434</td>\n",
       "      <td>35.604248</td>\n",
       "      <td>0.195457</td>\n",
       "      <td>33.089698</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>455.000000</td>\n",
       "      <td>530.000000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          TSH           T3          TT4          T4U  \\\n",
       "count  3771.000000  3403.000000  3003.000000  3541.000000  3385.000000   \n",
       "mean     51.735879     5.086766     2.013500   108.319345     0.995000   \n",
       "std      20.084958    24.521470     0.827434    35.604248     0.195457   \n",
       "min       1.000000     0.005000     0.050000     2.000000     0.250000   \n",
       "25%      36.000000     0.500000     1.600000    88.000000     0.880000   \n",
       "50%      54.000000     1.400000     2.000000   103.000000     0.980000   \n",
       "75%      67.000000     2.700000     2.400000   124.000000     1.080000   \n",
       "max     455.000000   530.000000    10.600000   430.000000     2.320000   \n",
       "\n",
       "               FTI  TBG  \n",
       "count  3387.000000  0.0  \n",
       "mean    110.469649  NaN  \n",
       "std      33.089698  NaN  \n",
       "min       2.000000  NaN  \n",
       "25%      93.000000  NaN  \n",
       "50%     107.000000  NaN  \n",
       "75%     124.000000  NaN  \n",
       "max     395.000000  NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>3622</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>2480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on_thyroxine</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_on_thyroxine</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on_antithyroid_medication</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sick</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pregnant</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thyroid_surgery</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I131_treatment</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_hypothyroid</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_hyperthyroid</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lithium</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goitre</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tumor</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypopituitary</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>psych</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>3588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSH_measured</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>3403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T3_measured</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>3003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TT4_measured</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>3541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T4U_measured</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>3385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FTI_measured</th>\n",
       "      <td>3772</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>3387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TBG_measured</th>\n",
       "      <td>3772</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>3772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>referral_source</th>\n",
       "      <td>3772</td>\n",
       "      <td>5</td>\n",
       "      <td>other</td>\n",
       "      <td>2201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count unique    top  freq\n",
       "sex                        3622      2      F  2480\n",
       "on_thyroxine               3772      2      f  3308\n",
       "query_on_thyroxine         3772      2      f  3722\n",
       "on_antithyroid_medication  3772      2      f  3729\n",
       "sick                       3772      2      f  3625\n",
       "pregnant                   3772      2      f  3719\n",
       "thyroid_surgery            3772      2      f  3719\n",
       "I131_treatment             3772      2      f  3713\n",
       "query_hypothyroid          3772      2      f  3538\n",
       "query_hyperthyroid         3772      2      f  3535\n",
       "lithium                    3772      2      f  3754\n",
       "goitre                     3772      2      f  3738\n",
       "tumor                      3772      2      f  3676\n",
       "hypopituitary              3772      2      f  3771\n",
       "psych                      3772      2      f  3588\n",
       "TSH_measured               3772      2      t  3403\n",
       "T3_measured                3772      2      t  3003\n",
       "TT4_measured               3772      2      t  3541\n",
       "T4U_measured               3772      2      t  3385\n",
       "FTI_measured               3772      2      t  3387\n",
       "TBG_measured               3772      1      f  3772\n",
       "referral_source            3772      5  other  2201"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe(include=['O']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "transforms = [\n",
    "    ('sex_tr', make_pipeline(SimpleImputer(strategy='most_frequent'),\n",
    "                                   OneHotEncoder()) , ['sex']),\n",
    "    ('on_thyroxine_tr', OneHotEncoder(), ['on_thyroxine']),\n",
    "    ('referral_source_tr', OneHotEncoder(), ['referral_source']),\n",
    "    ('age_tr', SimpleImputer(strategy='median'), ['age']),\n",
    "    ('TSH_tr', SimpleImputer(strategy='median'), ['TSH']),  \n",
    "    ('T3_tr', SimpleImputer(strategy='median'), ['T3']),\n",
    "    ('TT4_tr', SimpleImputer(strategy='median'), ['TT4']),\n",
    "    ('T4U_tr', SimpleImputer(strategy='median'), ['T4U']),\n",
    "    ('FTI_tr', SimpleImputer(strategy='median'), ['FTI']),\n",
    "]\n",
    "\n",
    "column_transformer = ColumnTransformer(transforms, remainder='drop', n_jobs=-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# Transform the data\n",
    "X_train = column_transformer.fit_transform(X_train)\n",
    "X_test = column_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "It was chosen to remove most of the columns, according to the following principle, columns with many empty values, columns that indicate the presence of data and columns where most of the data is the same. The median was taken according to the principle of substitution, because we could see outliers in the data affecting the average. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 <a id=\"task2_2\"></a> (0.7 points)\n",
    "\n",
    "Fit and compare 5 different models (use sklearn): Gradient Boosting, Random Forest, Decision Tree, SVM, Logitics Regression\n",
    "    \n",
    "* Choose one classification metric and justify your choice .\n",
    "* Compare the models using score on cross validation. Mind the class balance when choosing the cross validation. (You can read more about different CV strategies [here](https://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold))\n",
    "* Which model has the best performance? Which models overfit or underfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.212082</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.993197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210367</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.986395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.208793</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.996610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.209537</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.993197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.208496</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.989761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_f1  train_f1\n",
       "0  0.212082    0.001606  0.945946  0.993197\n",
       "1  0.210367    0.001602  0.833333  0.986395\n",
       "2  0.208793    0.001631  0.880000  0.996610\n",
       "3  0.209537    0.001535  0.833333  0.993197\n",
       "4  0.208496    0.001515  0.820513  0.989761"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "scores = {'f1' : make_scorer(f1_score)}\n",
    "\n",
    "gradientModel = GradientBoostingClassifier()\n",
    "cv_results_gradientBoosting = cross_validate(gradientModel, X_train, y_train, scoring=scores,\n",
    "                                             cv=StratifiedKFold(), n_jobs=-1, return_train_score=True)\n",
    "pd.DataFrame(cv_results_gradientBoosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.147588</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.151142</td>\n",
       "      <td>0.009936</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.149061</td>\n",
       "      <td>0.010002</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.148667</td>\n",
       "      <td>0.009951</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.149953</td>\n",
       "      <td>0.010144</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_f1  train_f1\n",
       "0  0.147588    0.009868  0.882353       1.0\n",
       "1  0.151142    0.009936  0.852941       1.0\n",
       "2  0.149061    0.010002  0.828571       1.0\n",
       "3  0.148667    0.009951  0.857143       1.0\n",
       "4  0.149953    0.010144  0.816901       1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomForestModel = RandomForestClassifier()\n",
    "cv_results_randomForest = cross_validate(randomForestModel, X_train, y_train, scoring=scores,\n",
    "                                         cv=StratifiedKFold(), n_jobs=-1, return_train_score=True)\n",
    "pd.DataFrame(cv_results_randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003589</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003070</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_f1  train_f1\n",
       "0  0.003589    0.000854  0.891892       1.0\n",
       "1  0.003058    0.000826  0.880000       1.0\n",
       "2  0.003091    0.000841  0.894737       1.0\n",
       "3  0.002931    0.000989  0.876712       1.0\n",
       "4  0.003070    0.000768  0.864865       1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decisionTreeModel = DecisionTreeClassifier()\n",
    "cv_results_decisionTree = cross_validate(decisionTreeModel, X_train, y_train, scoring=scores,\n",
    "                                         cv=StratifiedKFold(), n_jobs=-1, return_train_score=True)\n",
    "pd.DataFrame(cv_results_decisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042572</td>\n",
       "      <td>0.018782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.043444</td>\n",
       "      <td>0.018672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.044367</td>\n",
       "      <td>0.019108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045146</td>\n",
       "      <td>0.018926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041490</td>\n",
       "      <td>0.018454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_f1  train_f1\n",
       "0  0.042572    0.018782      0.0       0.0\n",
       "1  0.043444    0.018672      0.0       0.0\n",
       "2  0.044367    0.019108      0.0       0.0\n",
       "3  0.045146    0.018926      0.0       0.0\n",
       "4  0.041490    0.018454      0.0       0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "SVCModel = SVC()\n",
    "cv_results_SVC = cross_validate(SVCModel, X_train, y_train, scoring=scores,\n",
    "                                cv=StratifiedKFold(), n_jobs=-1, return_train_score=True)\n",
    "pd.DataFrame(cv_results_SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029553</td>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028242</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.682353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027508</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027536</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.663968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029120</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_f1  train_f1\n",
       "0  0.029553    0.000883  0.828571  0.666667\n",
       "1  0.028242    0.000891  0.557377  0.682353\n",
       "2  0.027508    0.000892  0.646154  0.687500\n",
       "3  0.027536    0.000884  0.596491  0.663968\n",
       "4  0.029120    0.000900  0.625000  0.702703"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegressionModel = LogisticRegression()\n",
    "cv_results_logisticRegression = cross_validate(logisticRegressionModel, X_train, y_train, scoring=scores,\n",
    "                                               cv=StratifiedKFold(), n_jobs=-1, return_train_score=True)\n",
    "pd.DataFrame(cv_results_logisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments \n",
    "\n",
    "To test the models we chose parameter f1 because we are solving the problem of binary classification and this metric is the best way to do it.\n",
    "The best results for f1 are shown by gradientBoosting. RandomForestClassifier and DecisionTreeClassifier, even though they were faster, showed less good values. The worst results were showen by SVM and LogisticRegression.\n",
    "\n",
    "As for overfit, it can be seen in a not very strong form in RandomForestClassifier and DecisionTreeClassifier, as on the trained sample f1 shows 1 on the test sample much less. LogisticRegression clearly underfit and shows disgusting parameters everywhere. As for SVM, it just works strangely and assigning 0 to everything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 <a id=\"task2_3\"></a> (0.5 points)\n",
    "\n",
    "More Gradient Boosting. Choose one of the tree popular boosting implementations (xgboost, lightgbm, catboost). Select hyperparameters (number of trees, learning rate, depth) on cross-validation and compare with the methods from the previous task. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 175 candidates, totalling 875 fits\n",
      "0:\tlearn: 0.6127994\ttotal: 58.8ms\tremaining: 5.53s\n",
      "1:\tlearn: 0.5447024\ttotal: 61.3ms\tremaining: 2.85s\n",
      "2:\tlearn: 0.4878271\ttotal: 63.6ms\tremaining: 1.95s\n",
      "3:\tlearn: 0.4422982\ttotal: 66.3ms\tremaining: 1.51s\n",
      "4:\tlearn: 0.4004218\ttotal: 68.6ms\tremaining: 1.23s\n",
      "5:\tlearn: 0.3621398\ttotal: 70.9ms\tremaining: 1.05s\n",
      "6:\tlearn: 0.3299361\ttotal: 73.2ms\tremaining: 920ms\n",
      "7:\tlearn: 0.3008512\ttotal: 75.5ms\tremaining: 821ms\n",
      "8:\tlearn: 0.2772166\ttotal: 77.8ms\tremaining: 743ms\n",
      "9:\tlearn: 0.2553738\ttotal: 80.2ms\tremaining: 681ms\n",
      "10:\tlearn: 0.2337176\ttotal: 80.9ms\tremaining: 618ms\n",
      "11:\tlearn: 0.2150528\ttotal: 83.2ms\tremaining: 575ms\n",
      "12:\tlearn: 0.1986301\ttotal: 85.6ms\tremaining: 540ms\n",
      "13:\tlearn: 0.1857192\ttotal: 87.8ms\tremaining: 508ms\n",
      "14:\tlearn: 0.1721373\ttotal: 90.1ms\tremaining: 480ms\n",
      "15:\tlearn: 0.1603820\ttotal: 92.4ms\tremaining: 456ms\n",
      "16:\tlearn: 0.1495572\ttotal: 94.7ms\tremaining: 435ms\n",
      "17:\tlearn: 0.1398867\ttotal: 97.1ms\tremaining: 415ms\n",
      "18:\tlearn: 0.1320785\ttotal: 99.5ms\tremaining: 398ms\n",
      "19:\tlearn: 0.1237080\ttotal: 102ms\tremaining: 382ms\n",
      "20:\tlearn: 0.1157621\ttotal: 104ms\tremaining: 366ms\n",
      "21:\tlearn: 0.1100985\ttotal: 106ms\tremaining: 353ms\n",
      "22:\tlearn: 0.1037802\ttotal: 107ms\tremaining: 335ms\n",
      "23:\tlearn: 0.0977935\ttotal: 110ms\tremaining: 325ms\n",
      "24:\tlearn: 0.0933786\ttotal: 112ms\tremaining: 314ms\n",
      "25:\tlearn: 0.0886307\ttotal: 115ms\tremaining: 304ms\n",
      "26:\tlearn: 0.0840743\ttotal: 117ms\tremaining: 294ms\n",
      "27:\tlearn: 0.0804964\ttotal: 119ms\tremaining: 286ms\n",
      "28:\tlearn: 0.0772740\ttotal: 122ms\tremaining: 277ms\n",
      "29:\tlearn: 0.0737331\ttotal: 124ms\tremaining: 269ms\n",
      "30:\tlearn: 0.0703678\ttotal: 126ms\tremaining: 261ms\n",
      "31:\tlearn: 0.0679402\ttotal: 129ms\tremaining: 254ms\n",
      "32:\tlearn: 0.0655129\ttotal: 131ms\tremaining: 247ms\n",
      "33:\tlearn: 0.0634123\ttotal: 134ms\tremaining: 240ms\n",
      "34:\tlearn: 0.0607204\ttotal: 136ms\tremaining: 233ms\n",
      "35:\tlearn: 0.0588475\ttotal: 138ms\tremaining: 227ms\n",
      "36:\tlearn: 0.0573523\ttotal: 141ms\tremaining: 221ms\n",
      "37:\tlearn: 0.0551686\ttotal: 143ms\tremaining: 215ms\n",
      "38:\tlearn: 0.0532311\ttotal: 145ms\tremaining: 209ms\n",
      "39:\tlearn: 0.0518161\ttotal: 148ms\tremaining: 203ms\n",
      "40:\tlearn: 0.0505960\ttotal: 150ms\tremaining: 197ms\n",
      "41:\tlearn: 0.0489596\ttotal: 152ms\tremaining: 192ms\n",
      "42:\tlearn: 0.0479587\ttotal: 155ms\tremaining: 187ms\n",
      "43:\tlearn: 0.0465157\ttotal: 157ms\tremaining: 182ms\n",
      "44:\tlearn: 0.0456585\ttotal: 159ms\tremaining: 177ms\n",
      "45:\tlearn: 0.0450251\ttotal: 162ms\tremaining: 172ms\n",
      "46:\tlearn: 0.0442428\ttotal: 164ms\tremaining: 168ms\n",
      "47:\tlearn: 0.0432916\ttotal: 167ms\tremaining: 163ms\n",
      "48:\tlearn: 0.0421927\ttotal: 169ms\tremaining: 159ms\n",
      "49:\tlearn: 0.0410777\ttotal: 172ms\tremaining: 154ms\n",
      "50:\tlearn: 0.0399243\ttotal: 174ms\tremaining: 150ms\n",
      "51:\tlearn: 0.0390594\ttotal: 176ms\tremaining: 146ms\n",
      "52:\tlearn: 0.0383255\ttotal: 179ms\tremaining: 142ms\n",
      "53:\tlearn: 0.0378411\ttotal: 181ms\tremaining: 137ms\n",
      "54:\tlearn: 0.0367817\ttotal: 183ms\tremaining: 133ms\n",
      "55:\tlearn: 0.0362768\ttotal: 186ms\tremaining: 129ms\n",
      "56:\tlearn: 0.0357408\ttotal: 188ms\tremaining: 125ms\n",
      "57:\tlearn: 0.0349836\ttotal: 190ms\tremaining: 121ms\n",
      "58:\tlearn: 0.0343364\ttotal: 193ms\tremaining: 118ms\n",
      "59:\tlearn: 0.0331806\ttotal: 195ms\tremaining: 114ms\n",
      "60:\tlearn: 0.0327161\ttotal: 197ms\tremaining: 110ms\n",
      "61:\tlearn: 0.0317663\ttotal: 200ms\tremaining: 106ms\n",
      "62:\tlearn: 0.0315269\ttotal: 202ms\tremaining: 103ms\n",
      "63:\tlearn: 0.0313458\ttotal: 204ms\tremaining: 99ms\n",
      "64:\tlearn: 0.0310744\ttotal: 207ms\tremaining: 95.4ms\n",
      "65:\tlearn: 0.0307842\ttotal: 209ms\tremaining: 91.9ms\n",
      "66:\tlearn: 0.0299242\ttotal: 211ms\tremaining: 88.3ms\n",
      "67:\tlearn: 0.0295479\ttotal: 214ms\tremaining: 84.8ms\n",
      "68:\tlearn: 0.0289236\ttotal: 216ms\tremaining: 81.4ms\n",
      "69:\tlearn: 0.0285121\ttotal: 218ms\tremaining: 78ms\n",
      "70:\tlearn: 0.0279451\ttotal: 221ms\tremaining: 74.6ms\n",
      "71:\tlearn: 0.0274418\ttotal: 223ms\tremaining: 71.3ms\n",
      "72:\tlearn: 0.0270237\ttotal: 226ms\tremaining: 68ms\n",
      "73:\tlearn: 0.0267844\ttotal: 228ms\tremaining: 64.7ms\n",
      "74:\tlearn: 0.0266010\ttotal: 230ms\tremaining: 61.4ms\n",
      "75:\tlearn: 0.0262979\ttotal: 232ms\tremaining: 58.1ms\n",
      "76:\tlearn: 0.0261393\ttotal: 235ms\tremaining: 54.9ms\n",
      "77:\tlearn: 0.0260183\ttotal: 237ms\tremaining: 51.6ms\n",
      "78:\tlearn: 0.0258299\ttotal: 239ms\tremaining: 48.5ms\n",
      "79:\tlearn: 0.0256391\ttotal: 242ms\tremaining: 45.3ms\n",
      "80:\tlearn: 0.0255088\ttotal: 244ms\tremaining: 42.2ms\n",
      "81:\tlearn: 0.0252477\ttotal: 246ms\tremaining: 39.1ms\n",
      "82:\tlearn: 0.0247268\ttotal: 249ms\tremaining: 36.1ms\n",
      "83:\tlearn: 0.0243128\ttotal: 252ms\tremaining: 33ms\n",
      "84:\tlearn: 0.0239372\ttotal: 254ms\tremaining: 29.9ms\n",
      "85:\tlearn: 0.0235479\ttotal: 257ms\tremaining: 26.9ms\n",
      "86:\tlearn: 0.0233124\ttotal: 259ms\tremaining: 23.9ms\n",
      "87:\tlearn: 0.0229936\ttotal: 262ms\tremaining: 20.8ms\n",
      "88:\tlearn: 0.0226966\ttotal: 264ms\tremaining: 17.8ms\n",
      "89:\tlearn: 0.0223743\ttotal: 267ms\tremaining: 14.8ms\n",
      "90:\tlearn: 0.0222493\ttotal: 269ms\tremaining: 11.8ms\n",
      "91:\tlearn: 0.0221389\ttotal: 272ms\tremaining: 8.86ms\n",
      "92:\tlearn: 0.0219630\ttotal: 274ms\tremaining: 5.9ms\n",
      "93:\tlearn: 0.0217892\ttotal: 277ms\tremaining: 2.95ms\n",
      "94:\tlearn: 0.0216902\ttotal: 280ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'depth': 9, 'iterations': 95, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "parameters = {'iterations' : range(90, 111, 5), \n",
    "              'learning_rate' : np.linspace(0.01,0.1,7), \n",
    "              'depth' : range(5, 15, 2)}\n",
    "\n",
    "modelCat = CatBoostClassifier()\n",
    "clf = GridSearchCV(modelCat, parameters, verbose=10, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.480127</td>\n",
       "      <td>0.007061</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.957746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.480912</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>0.965035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.479405</td>\n",
       "      <td>0.006712</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.957746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.473338</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.954064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.478487</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.972603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_f1  train_f1\n",
       "0  0.480127    0.007061  0.957746  0.957746\n",
       "1  0.480912    0.006723  0.873239  0.965035\n",
       "2  0.479405    0.006712  0.901408  0.957746\n",
       "3  0.473338    0.006185  0.888889  0.954064\n",
       "4  0.478487    0.004462  0.815789  0.972603"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelCat = modelCat = CatBoostClassifier(iterations=clf.best_params_['iterations'],\n",
    "                                         learning_rate=clf.best_params_['learning_rate'],\n",
    "                                         depth=clf.best_params_['depth'])\n",
    "cv_results_modelCat = cross_validate(modelCat, X_train, y_train, scoring=scores,\n",
    "                                               cv=StratifiedKFold(), n_jobs=-1, return_train_score=True)\n",
    "pd.DataFrame(cv_results_modelCat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "From the results we can see that a careful selection of hyperparameters and the use of catboost implementation, can significantly improve the performance. But at the same time there is a decrease in the learning time by more than 2 times. No overfit or underfit was observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 <a id=\"task2_4\"></a> (0.7 points)\n",
    "\n",
    "Now let's train more fancy ensembles:\n",
    "\n",
    "* Bagging with decision trees as base estimators\n",
    "* Bagging with gradient boosting (with large amount of trees, >100) as base estimators\n",
    "* [Voting classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier) \n",
    "* [Stacking Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier) with Logistic Regression as a final model\n",
    "* [Stacking Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier) with Gradeint Boosting as a final model\n",
    "\n",
    "\n",
    "If not stated in the task, feel free to tune / choose hyperparameters and base models.\n",
    "\n",
    "Answer the questions:\n",
    "* Which model has the best performance?\n",
    "* Does bagging reduce overfiting of the gradient boosting with large amount of trees? \n",
    "* What is the difference between voting and staking? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028700</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.979310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027148</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.989761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027872</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.982935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028535</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.996610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028144</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.983051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_f1  train_f1\n",
       "0  0.028700    0.002116  0.916667  0.979310\n",
       "1  0.027148    0.002081  0.898551  0.989761\n",
       "2  0.027872    0.002488  0.901408  0.982935\n",
       "3  0.028535    0.003546  0.888889  0.996610\n",
       "4  0.028144    0.002020  0.849315  0.983051"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "baggingClassifierModel = BaggingClassifier()\n",
    "cv_results_baggingClassifier = cross_validate(baggingClassifierModel, X_train, y_train, scoring=scores,\n",
    "                                               cv=StratifiedKFold(), n_jobs=-1, return_train_score=True)\n",
    "pd.DataFrame(cv_results_baggingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.279422</td>\n",
       "      <td>0.011073</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.972789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.274999</td>\n",
       "      <td>0.010977</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.993243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.285376</td>\n",
       "      <td>0.010850</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.993243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.295550</td>\n",
       "      <td>0.010206</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.989761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.278953</td>\n",
       "      <td>0.010769</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.989761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_f1  train_f1\n",
       "0  2.279422    0.011073  0.901408  0.972789\n",
       "1  2.274999    0.010977  0.864865  0.993243\n",
       "2  2.285376    0.010850  0.880000  0.993243\n",
       "3  2.295550    0.010206  0.857143  0.989761\n",
       "4  2.278953    0.010769  0.826667  0.989761"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baggingClassifierGradBoostingModel = BaggingClassifier(base_estimator=GradientBoostingClassifier(n_estimators=150))\n",
    "cv_results_baggingClassifierGradBoosting = cross_validate(baggingClassifierGradBoostingModel, X_train, y_train,\n",
    "                                                          scoring=scores, cv=StratifiedKFold(), n_jobs=-1,\n",
    "                                                          return_train_score=True)\n",
    "pd.DataFrame(cv_results_baggingClassifierGradBoosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.360385</td>\n",
       "      <td>0.013644</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.363041</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.363229</td>\n",
       "      <td>0.013674</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.360623</td>\n",
       "      <td>0.013380</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.357591</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_f1  train_f1\n",
       "0  0.360385    0.013644  0.944444       1.0\n",
       "1  0.363041    0.013774  0.857143       1.0\n",
       "2  0.363229    0.013674  0.888889       1.0\n",
       "3  0.360623    0.013380  0.876712       1.0\n",
       "4  0.357591    0.013437  0.842105       1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = GradientBoostingClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = DecisionTreeClassifier()\n",
    "\n",
    "estimators = [('gb', clf1), ('rf', clf2), ('dt', clf3)]\n",
    "\n",
    "votingModel = VotingClassifier(estimators=estimators)\n",
    "cv_results_voting = cross_validate(votingModel, X_train, y_train, scoring=scores,\n",
    "                                               cv=StratifiedKFold(), n_jobs=-1, return_train_score=True)\n",
    "pd.DataFrame(cv_results_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.956847</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.953310</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.002033</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>0.873239</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.946277</td>\n",
       "      <td>0.010608</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.941720</td>\n",
       "      <td>0.010935</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.99661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_f1  train_f1\n",
       "0  1.956847    0.010789  0.898551   1.00000\n",
       "1  1.953310    0.010719  0.911765   1.00000\n",
       "2  2.002033    0.011226  0.873239   1.00000\n",
       "3  1.946277    0.010608  0.840580   1.00000\n",
       "4  1.941720    0.010935  0.864865   0.99661"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "stakingLRModel = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "cv_results_stakingLR = cross_validate(stakingLRModel, X_train, y_train, scoring=scores,\n",
    "                                               cv=StratifiedKFold(), n_jobs=-1, return_train_score=True)\n",
    "pd.DataFrame(cv_results_stakingLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.937352</td>\n",
       "      <td>0.010935</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.932863</td>\n",
       "      <td>0.011086</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.996633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.927517</td>\n",
       "      <td>0.010736</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.927748</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.927264</td>\n",
       "      <td>0.010725</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.989967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_f1  train_f1\n",
       "0  0.937352    0.010935  0.931507  1.000000\n",
       "1  0.932863    0.011086  0.853333  0.996633\n",
       "2  0.927517    0.010736  0.837838  1.000000\n",
       "3  0.927748    0.010606  0.888889  1.000000\n",
       "4  0.927264    0.010725  0.833333  0.989967"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stakingGBModel = StackingClassifier(estimators=[('rf', clf2), ('dt', clf3)], \n",
    "                                    final_estimator=GradientBoostingClassifier())\n",
    "cv_results_stakingGB = cross_validate(stakingGBModel, X_train, y_train, scoring=scores,\n",
    "                                               cv=StratifiedKFold(), n_jobs=-1, return_train_score=True)\n",
    "pd.DataFrame(cv_results_stakingGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "The best performance show Voting Classifier with GradientBoostingClassifier, RandomForestClassifier and DecisionTreeClassifier. Nearly same performance show stacking models with different final estimators. Bagging a hardly improve overfiting situation with decision trees but didn't show much effect on Gradient Boosting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voting VS staking\n",
    "\n",
    "The idea of both classifiers is combining different estimators for taking advantages from all of them. The main differance is in the way of combining estimators. VotingClassifier use a majority vote or the average predicted probabilities to predict the class labels. While StackingClassifier use predictions of each individual estimator as input to a final estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 <a id=\"task2_5\"></a> (0.1 points)\n",
    "\n",
    "Report the test score for the best model, that you were able to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.478454</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>0.887415</td>\n",
       "      <td>0.961439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time   test_f1  train_f1\n",
       "0  0.478454    0.006229  0.887415  0.961439"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_score = {'fit_time': [cv_results_modelCat['fit_time'].mean()],\n",
    "               'score_time': [cv_results_modelCat['score_time'].mean()],\n",
    "               'test_f1': [cv_results_modelCat['test_f1'].mean()],\n",
    "               'train_f1': [cv_results_modelCat['train_f1'].mean()]}\n",
    "\n",
    "pd.DataFrame(final_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "The best model I was able to train is CatBoostClassifier with depth = 9, iterations = 95 and learning_rate = 0.1.\n",
    "\n",
    "I think this model show so good results because I find it hyperparameters with Grid Search, but of course it is really nice model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
